{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0:\n",
    "Data and goal\n",
    "Kaggle project, maximize roc curve (but use gini for evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1: research\n",
    "Before I type a line of code, I need to understand my problem, what approaches other data scientists have used. \n",
    "Reading papers, etc. \n",
    "Because kaggle is a collaborative community,  I'm focusing my research on other posted kaggle kernels. \n",
    "\n",
    "This is a strange problem: To protect customer privacy all data has been anonomized, so there's no way to add domain knowledge in feature engineering. \n",
    "As a kaggle competition, there are none of the 'real world' concerns about model implementation, computational costs.\n",
    "This is also a highly imbalanced problem (1s are much more common than 0s).\n",
    "I'm going to use this as an example of the standard kaggle workflow: \n",
    "Stack  a few different types of boosted tries (extensively hyperparameter tuned)\n",
    "\n",
    "\n",
    "https://www.kaggle.com/pavetr/stacking-lb-0-285  shows a full stack of multiple models, this is the 'kaggle' approach in a nutshell in all of it's glory (don't feature engineer, make another model and stack them)\n",
    "\n",
    "https://www.kaggle.com/ogrellier/feature-selection-target-permutations talks about feature permutations (to help with feature engineering)\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/  (how to hyperparamter tune xgboost)\n",
    "\n",
    "https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial  EDA tutorial\n",
    "\n",
    "https://codesachin.wordpress.com/2016/06/25/non-mathematical-feature-engineering-techniques-for-data-science/\n",
    "\n",
    "\n",
    "My procedure: Use three models (Xgboost, LGBM, Catboost), and use a simple average. \n",
    "As a bonus test, I'll make  an LR  that takes as input the outputs  from the three models and returns an output that is the target. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data loading, library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/opt/data/tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import set_start_method\n",
    "set_start_method(\"forkserver\")\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"26\" # I run this on  a dual e-52670 (16 core, 32 thread) box. This gives the os 6 threads to play with. \n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/opt/data/tmp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.5/dist-packages (from plotly)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.5/dist-packages (from plotly)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from plotly)\n",
      "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.5/dist-packages (from plotly)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from plotly)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests->plotly)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests->plotly)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests->plotly)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests->plotly)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.5/dist-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.5/dist-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.5/dist-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.5/dist-packages (from nbformat>=4.2->plotly)\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.5/dist-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from xgboost)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from xgboost)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from xgboost)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from lightgbm)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from lightgbm)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from lightgbm)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from catboost)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from catboost)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /usr/local/lib/python3.5/dist-packages\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from numba)\r\n",
      "Requirement already satisfied: llvmlite in /usr/local/lib/python3.5/dist-packages (from numba)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Gini metric, this competition uses an uncommmon evaluation metric, so we should define it\n",
    "\n",
    "@jit  # for more info please visit https://numba.pydata.org/\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Original author CMPM \n",
    "    https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: EDA\n",
    "I'm going to do something a little different from \"standard\" eda. I'm merely going to focus on feature importance and use that to build some new features, as well as cull features that aren't adding information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "# from https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial we can see a method of feature improtance using random forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training Done -----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\n",
    "rf.fit(train.drop(['id', 'target'],axis=1), train.target)\n",
    "features = train.drop(['id', 'target'],axis=1).columns.values\n",
    "print(\"----- Training Done -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           0.01686434542269142,
           0.011053805247045436,
           0.036219170535060755,
           0.019470566624956092,
           0.07861381065229754,
           0.019871398042689628,
           0.02209323746126317,
           0.004198705181889577,
           0.003607748989459628,
           0.0003743181308508165,
           0.000658587568488969,
           0.0013468714834950239,
           0.0006631273358967262,
           0.002396248137555366,
           0.02559893166563769,
           0.013920353817181067,
           0.056972129046208644,
           0.002157913151265299,
           0.016475991648979886,
           0.038131333126062074,
           0.07169756523163816,
           0.025542700975322873,
           0.009404375939580238,
           0.02143813341563879,
           0.028014375170701815,
           0.006161484578645829,
           0.013635548698960633,
           0.031616018789628386,
           0.0033942424985942323,
           0.00931835490969756,
           0.001989572452739753,
           0.0169000533930654,
           0.006131305051533334,
           0.026575212817247448,
           0.12972589668605977,
           0.027730687462900114,
           0.018552997743760267,
           0.012009756930235212,
           0.012160372455969666,
           0.011576231652990453,
           0.008128745850432492,
           0.010594230122584794,
           0.00859806923363534,
           0.011555325103106582,
           0.01014094472565096,
           0.00976021723144253,
           0.019068010059436213,
           0.015948843121933284,
           0.010077793671110571,
           0.011709915331607012,
           0.01718398425858274,
           0.001870133874931154,
           0.002257450267841548,
           0.002469687345810993,
           0.0024558305914006385,
           0.0026302488825493274,
           0.0012870902040590282
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 13,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "ps_ind_01",
          "ps_ind_02_cat",
          "ps_ind_03",
          "ps_ind_04_cat",
          "ps_ind_05_cat",
          "ps_ind_06_bin",
          "ps_ind_07_bin",
          "ps_ind_08_bin",
          "ps_ind_09_bin",
          "ps_ind_10_bin",
          "ps_ind_11_bin",
          "ps_ind_12_bin",
          "ps_ind_13_bin",
          "ps_ind_14",
          "ps_ind_15",
          "ps_ind_16_bin",
          "ps_ind_17_bin",
          "ps_ind_18_bin",
          "ps_reg_01",
          "ps_reg_02",
          "ps_reg_03",
          "ps_car_01_cat",
          "ps_car_02_cat",
          "ps_car_03_cat",
          "ps_car_04_cat",
          "ps_car_05_cat",
          "ps_car_06_cat",
          "ps_car_07_cat",
          "ps_car_08_cat",
          "ps_car_09_cat",
          "ps_car_10_cat",
          "ps_car_11_cat",
          "ps_car_11",
          "ps_car_12",
          "ps_car_13",
          "ps_car_14",
          "ps_car_15",
          "ps_calc_01",
          "ps_calc_02",
          "ps_calc_03",
          "ps_calc_04",
          "ps_calc_05",
          "ps_calc_06",
          "ps_calc_07",
          "ps_calc_08",
          "ps_calc_09",
          "ps_calc_10",
          "ps_calc_11",
          "ps_calc_12",
          "ps_calc_13",
          "ps_calc_14",
          "ps_calc_15_bin",
          "ps_calc_16_bin",
          "ps_calc_17_bin",
          "ps_calc_18_bin",
          "ps_calc_19_bin",
          "ps_calc_20_bin"
         ],
         "type": "scatter",
         "x": [
          "ps_ind_01",
          "ps_ind_02_cat",
          "ps_ind_03",
          "ps_ind_04_cat",
          "ps_ind_05_cat",
          "ps_ind_06_bin",
          "ps_ind_07_bin",
          "ps_ind_08_bin",
          "ps_ind_09_bin",
          "ps_ind_10_bin",
          "ps_ind_11_bin",
          "ps_ind_12_bin",
          "ps_ind_13_bin",
          "ps_ind_14",
          "ps_ind_15",
          "ps_ind_16_bin",
          "ps_ind_17_bin",
          "ps_ind_18_bin",
          "ps_reg_01",
          "ps_reg_02",
          "ps_reg_03",
          "ps_car_01_cat",
          "ps_car_02_cat",
          "ps_car_03_cat",
          "ps_car_04_cat",
          "ps_car_05_cat",
          "ps_car_06_cat",
          "ps_car_07_cat",
          "ps_car_08_cat",
          "ps_car_09_cat",
          "ps_car_10_cat",
          "ps_car_11_cat",
          "ps_car_11",
          "ps_car_12",
          "ps_car_13",
          "ps_car_14",
          "ps_car_15",
          "ps_calc_01",
          "ps_calc_02",
          "ps_calc_03",
          "ps_calc_04",
          "ps_calc_05",
          "ps_calc_06",
          "ps_calc_07",
          "ps_calc_08",
          "ps_calc_09",
          "ps_calc_10",
          "ps_calc_11",
          "ps_calc_12",
          "ps_calc_13",
          "ps_calc_14",
          "ps_calc_15_bin",
          "ps_calc_16_bin",
          "ps_calc_17_bin",
          "ps_calc_18_bin",
          "ps_calc_19_bin",
          "ps_calc_20_bin"
         ],
         "y": [
          0.01686434542269142,
          0.011053805247045436,
          0.036219170535060755,
          0.019470566624956092,
          0.07861381065229754,
          0.019871398042689628,
          0.02209323746126317,
          0.004198705181889577,
          0.003607748989459628,
          0.0003743181308508165,
          0.000658587568488969,
          0.0013468714834950239,
          0.0006631273358967262,
          0.002396248137555366,
          0.02559893166563769,
          0.013920353817181067,
          0.056972129046208644,
          0.002157913151265299,
          0.016475991648979886,
          0.038131333126062074,
          0.07169756523163816,
          0.025542700975322873,
          0.009404375939580238,
          0.02143813341563879,
          0.028014375170701815,
          0.006161484578645829,
          0.013635548698960633,
          0.031616018789628386,
          0.0033942424985942323,
          0.00931835490969756,
          0.001989572452739753,
          0.0169000533930654,
          0.006131305051533334,
          0.026575212817247448,
          0.12972589668605977,
          0.027730687462900114,
          0.018552997743760267,
          0.012009756930235212,
          0.012160372455969666,
          0.011576231652990453,
          0.008128745850432492,
          0.010594230122584794,
          0.00859806923363534,
          0.011555325103106582,
          0.01014094472565096,
          0.00976021723144253,
          0.019068010059436213,
          0.015948843121933284,
          0.010077793671110571,
          0.011709915331607012,
          0.01718398425858274,
          0.001870133874931154,
          0.002257450267841548,
          0.002469687345810993,
          0.0024558305914006385,
          0.0026302488825493274,
          0.0012870902040590282
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Random Forest Feature Importance",
        "xaxis": {
         "showgrid": false,
         "showline": false,
         "ticklen": 5,
         "zeroline": false
        },
        "yaxis": {
         "gridwidth": 2,
         "showgrid": false,
         "ticklen": 5,
         "title": "Feature Importance",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"d4f1916f-dc3f-4567-be0f-6ed35483a3ec\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d4f1916f-dc3f-4567-be0f-6ed35483a3ec\", [{\"text\": [\"ps_ind_01\", \"ps_ind_02_cat\", \"ps_ind_03\", \"ps_ind_04_cat\", \"ps_ind_05_cat\", \"ps_ind_06_bin\", \"ps_ind_07_bin\", \"ps_ind_08_bin\", \"ps_ind_09_bin\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_ind_14\", \"ps_ind_15\", \"ps_ind_16_bin\", \"ps_ind_17_bin\", \"ps_ind_18_bin\", \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\", \"ps_car_01_cat\", \"ps_car_02_cat\", \"ps_car_03_cat\", \"ps_car_04_cat\", \"ps_car_05_cat\", \"ps_car_06_cat\", \"ps_car_07_cat\", \"ps_car_08_cat\", \"ps_car_09_cat\", \"ps_car_10_cat\", \"ps_car_11_cat\", \"ps_car_11\", \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\", \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\", \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"], \"x\": [\"ps_ind_01\", \"ps_ind_02_cat\", \"ps_ind_03\", \"ps_ind_04_cat\", \"ps_ind_05_cat\", \"ps_ind_06_bin\", \"ps_ind_07_bin\", \"ps_ind_08_bin\", \"ps_ind_09_bin\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_ind_14\", \"ps_ind_15\", \"ps_ind_16_bin\", \"ps_ind_17_bin\", \"ps_ind_18_bin\", \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\", \"ps_car_01_cat\", \"ps_car_02_cat\", \"ps_car_03_cat\", \"ps_car_04_cat\", \"ps_car_05_cat\", \"ps_car_06_cat\", \"ps_car_07_cat\", \"ps_car_08_cat\", \"ps_car_09_cat\", \"ps_car_10_cat\", \"ps_car_11_cat\", \"ps_car_11\", \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\", \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\", \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"], \"marker\": {\"showscale\": true, \"color\": [0.01686434542269142, 0.011053805247045436, 0.036219170535060755, 0.019470566624956092, 0.07861381065229754, 0.019871398042689628, 0.02209323746126317, 0.004198705181889577, 0.003607748989459628, 0.0003743181308508165, 0.000658587568488969, 0.0013468714834950239, 0.0006631273358967262, 0.002396248137555366, 0.02559893166563769, 0.013920353817181067, 0.056972129046208644, 0.002157913151265299, 0.016475991648979886, 0.038131333126062074, 0.07169756523163816, 0.025542700975322873, 0.009404375939580238, 0.02143813341563879, 0.028014375170701815, 0.006161484578645829, 0.013635548698960633, 0.031616018789628386, 0.0033942424985942323, 0.00931835490969756, 0.001989572452739753, 0.0169000533930654, 0.006131305051533334, 0.026575212817247448, 0.12972589668605977, 0.027730687462900114, 0.018552997743760267, 0.012009756930235212, 0.012160372455969666, 0.011576231652990453, 0.008128745850432492, 0.010594230122584794, 0.00859806923363534, 0.011555325103106582, 0.01014094472565096, 0.00976021723144253, 0.019068010059436213, 0.015948843121933284, 0.010077793671110571, 0.011709915331607012, 0.01718398425858274, 0.001870133874931154, 0.002257450267841548, 0.002469687345810993, 0.0024558305914006385, 0.0026302488825493274, 0.0012870902040590282], \"size\": 13, \"sizeref\": 1, \"colorscale\": \"Portland\", \"sizemode\": \"diameter\"}, \"y\": [0.01686434542269142, 0.011053805247045436, 0.036219170535060755, 0.019470566624956092, 0.07861381065229754, 0.019871398042689628, 0.02209323746126317, 0.004198705181889577, 0.003607748989459628, 0.0003743181308508165, 0.000658587568488969, 0.0013468714834950239, 0.0006631273358967262, 0.002396248137555366, 0.02559893166563769, 0.013920353817181067, 0.056972129046208644, 0.002157913151265299, 0.016475991648979886, 0.038131333126062074, 0.07169756523163816, 0.025542700975322873, 0.009404375939580238, 0.02143813341563879, 0.028014375170701815, 0.006161484578645829, 0.013635548698960633, 0.031616018789628386, 0.0033942424985942323, 0.00931835490969756, 0.001989572452739753, 0.0169000533930654, 0.006131305051533334, 0.026575212817247448, 0.12972589668605977, 0.027730687462900114, 0.018552997743760267, 0.012009756930235212, 0.012160372455969666, 0.011576231652990453, 0.008128745850432492, 0.010594230122584794, 0.00859806923363534, 0.011555325103106582, 0.01014094472565096, 0.00976021723144253, 0.019068010059436213, 0.015948843121933284, 0.010077793671110571, 0.011709915331607012, 0.01718398425858274, 0.001870133874931154, 0.002257450267841548, 0.002469687345810993, 0.0024558305914006385, 0.0026302488825493274, 0.0012870902040590282], \"mode\": \"markers\", \"type\": \"scatter\"}], {\"yaxis\": {\"zeroline\": false, \"ticklen\": 5, \"title\": \"Feature Importance\", \"gridwidth\": 2, \"showgrid\": false}, \"xaxis\": {\"zeroline\": false, \"showgrid\": false, \"ticklen\": 5, \"showline\": false}, \"showlegend\": false, \"autosize\": true, \"hovermode\": \"closest\", \"title\": \"Random Forest Feature Importance\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"d4f1916f-dc3f-4567-be0f-6ed35483a3ec\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d4f1916f-dc3f-4567-be0f-6ed35483a3ec\", [{\"text\": [\"ps_ind_01\", \"ps_ind_02_cat\", \"ps_ind_03\", \"ps_ind_04_cat\", \"ps_ind_05_cat\", \"ps_ind_06_bin\", \"ps_ind_07_bin\", \"ps_ind_08_bin\", \"ps_ind_09_bin\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_ind_14\", \"ps_ind_15\", \"ps_ind_16_bin\", \"ps_ind_17_bin\", \"ps_ind_18_bin\", \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\", \"ps_car_01_cat\", \"ps_car_02_cat\", \"ps_car_03_cat\", \"ps_car_04_cat\", \"ps_car_05_cat\", \"ps_car_06_cat\", \"ps_car_07_cat\", \"ps_car_08_cat\", \"ps_car_09_cat\", \"ps_car_10_cat\", \"ps_car_11_cat\", \"ps_car_11\", \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\", \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\", \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"], \"x\": [\"ps_ind_01\", \"ps_ind_02_cat\", \"ps_ind_03\", \"ps_ind_04_cat\", \"ps_ind_05_cat\", \"ps_ind_06_bin\", \"ps_ind_07_bin\", \"ps_ind_08_bin\", \"ps_ind_09_bin\", \"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_ind_13_bin\", \"ps_ind_14\", \"ps_ind_15\", \"ps_ind_16_bin\", \"ps_ind_17_bin\", \"ps_ind_18_bin\", \"ps_reg_01\", \"ps_reg_02\", \"ps_reg_03\", \"ps_car_01_cat\", \"ps_car_02_cat\", \"ps_car_03_cat\", \"ps_car_04_cat\", \"ps_car_05_cat\", \"ps_car_06_cat\", \"ps_car_07_cat\", \"ps_car_08_cat\", \"ps_car_09_cat\", \"ps_car_10_cat\", \"ps_car_11_cat\", \"ps_car_11\", \"ps_car_12\", \"ps_car_13\", \"ps_car_14\", \"ps_car_15\", \"ps_calc_01\", \"ps_calc_02\", \"ps_calc_03\", \"ps_calc_04\", \"ps_calc_05\", \"ps_calc_06\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_09\", \"ps_calc_10\", \"ps_calc_11\", \"ps_calc_12\", \"ps_calc_13\", \"ps_calc_14\", \"ps_calc_15_bin\", \"ps_calc_16_bin\", \"ps_calc_17_bin\", \"ps_calc_18_bin\", \"ps_calc_19_bin\", \"ps_calc_20_bin\"], \"marker\": {\"showscale\": true, \"color\": [0.01686434542269142, 0.011053805247045436, 0.036219170535060755, 0.019470566624956092, 0.07861381065229754, 0.019871398042689628, 0.02209323746126317, 0.004198705181889577, 0.003607748989459628, 0.0003743181308508165, 0.000658587568488969, 0.0013468714834950239, 0.0006631273358967262, 0.002396248137555366, 0.02559893166563769, 0.013920353817181067, 0.056972129046208644, 0.002157913151265299, 0.016475991648979886, 0.038131333126062074, 0.07169756523163816, 0.025542700975322873, 0.009404375939580238, 0.02143813341563879, 0.028014375170701815, 0.006161484578645829, 0.013635548698960633, 0.031616018789628386, 0.0033942424985942323, 0.00931835490969756, 0.001989572452739753, 0.0169000533930654, 0.006131305051533334, 0.026575212817247448, 0.12972589668605977, 0.027730687462900114, 0.018552997743760267, 0.012009756930235212, 0.012160372455969666, 0.011576231652990453, 0.008128745850432492, 0.010594230122584794, 0.00859806923363534, 0.011555325103106582, 0.01014094472565096, 0.00976021723144253, 0.019068010059436213, 0.015948843121933284, 0.010077793671110571, 0.011709915331607012, 0.01718398425858274, 0.001870133874931154, 0.002257450267841548, 0.002469687345810993, 0.0024558305914006385, 0.0026302488825493274, 0.0012870902040590282], \"size\": 13, \"sizeref\": 1, \"colorscale\": \"Portland\", \"sizemode\": \"diameter\"}, \"y\": [0.01686434542269142, 0.011053805247045436, 0.036219170535060755, 0.019470566624956092, 0.07861381065229754, 0.019871398042689628, 0.02209323746126317, 0.004198705181889577, 0.003607748989459628, 0.0003743181308508165, 0.000658587568488969, 0.0013468714834950239, 0.0006631273358967262, 0.002396248137555366, 0.02559893166563769, 0.013920353817181067, 0.056972129046208644, 0.002157913151265299, 0.016475991648979886, 0.038131333126062074, 0.07169756523163816, 0.025542700975322873, 0.009404375939580238, 0.02143813341563879, 0.028014375170701815, 0.006161484578645829, 0.013635548698960633, 0.031616018789628386, 0.0033942424985942323, 0.00931835490969756, 0.001989572452739753, 0.0169000533930654, 0.006131305051533334, 0.026575212817247448, 0.12972589668605977, 0.027730687462900114, 0.018552997743760267, 0.012009756930235212, 0.012160372455969666, 0.011576231652990453, 0.008128745850432492, 0.010594230122584794, 0.00859806923363534, 0.011555325103106582, 0.01014094472565096, 0.00976021723144253, 0.019068010059436213, 0.015948843121933284, 0.010077793671110571, 0.011709915331607012, 0.01718398425858274, 0.001870133874931154, 0.002257450267841548, 0.002469687345810993, 0.0024558305914006385, 0.0026302488825493274, 0.0012870902040590282], \"mode\": \"markers\", \"type\": \"scatter\"}], {\"yaxis\": {\"zeroline\": false, \"ticklen\": 5, \"title\": \"Feature Importance\", \"gridwidth\": 2, \"showgrid\": false}, \"xaxis\": {\"zeroline\": false, \"showgrid\": false, \"ticklen\": 5, \"showline\": false}, \"showlegend\": false, \"autosize\": true, \"hovermode\": \"closest\", \"title\": \"Random Forest Feature Importance\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = rf.feature_importances_,\n",
    "    x = features,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 13,\n",
    "        #size= rf.feature_importances_,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = rf.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = features\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Random Forest Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 5,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           0.0003743181308508165,
           0.000658587568488969,
           0.0006631273358967262,
           0.0012870902040590282,
           0.0013468714834950239,
           0.001870133874931154,
           0.001989572452739753,
           0.002157913151265299,
           0.002257450267841548,
           0.002396248137555366,
           0.0024558305914006385,
           0.002469687345810993,
           0.0026302488825493274,
           0.0033942424985942323,
           0.003607748989459628,
           0.004198705181889577,
           0.006131305051533334,
           0.006161484578645829,
           0.008128745850432492,
           0.00859806923363534,
           0.00931835490969756,
           0.009404375939580238,
           0.00976021723144253,
           0.010077793671110571,
           0.01014094472565096,
           0.010594230122584794,
           0.011053805247045436,
           0.011555325103106582,
           0.011576231652990453,
           0.011709915331607012,
           0.012009756930235212,
           0.012160372455969666,
           0.013635548698960633,
           0.013920353817181067,
           0.015948843121933284,
           0.016475991648979886,
           0.01686434542269142,
           0.0169000533930654,
           0.01718398425858274,
           0.018552997743760267,
           0.019068010059436213,
           0.019470566624956092,
           0.019871398042689628,
           0.02143813341563879,
           0.02209323746126317,
           0.025542700975322873,
           0.02559893166563769,
           0.026575212817247448,
           0.027730687462900114,
           0.028014375170701815,
           0.031616018789628386,
           0.036219170535060755,
           0.038131333126062074,
           0.056972129046208644,
           0.07169756523163816,
           0.07861381065229754,
           0.12972589668605977
          ],
          "colorscale": "Viridis",
          "reversescale": true
         },
         "name": "Random Forest Feature importance",
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0003743181308508165,
          0.000658587568488969,
          0.0006631273358967262,
          0.0012870902040590282,
          0.0013468714834950239,
          0.001870133874931154,
          0.001989572452739753,
          0.002157913151265299,
          0.002257450267841548,
          0.002396248137555366,
          0.0024558305914006385,
          0.002469687345810993,
          0.0026302488825493274,
          0.0033942424985942323,
          0.003607748989459628,
          0.004198705181889577,
          0.006131305051533334,
          0.006161484578645829,
          0.008128745850432492,
          0.00859806923363534,
          0.00931835490969756,
          0.009404375939580238,
          0.00976021723144253,
          0.010077793671110571,
          0.01014094472565096,
          0.010594230122584794,
          0.011053805247045436,
          0.011555325103106582,
          0.011576231652990453,
          0.011709915331607012,
          0.012009756930235212,
          0.012160372455969666,
          0.013635548698960633,
          0.013920353817181067,
          0.015948843121933284,
          0.016475991648979886,
          0.01686434542269142,
          0.0169000533930654,
          0.01718398425858274,
          0.018552997743760267,
          0.019068010059436213,
          0.019470566624956092,
          0.019871398042689628,
          0.02143813341563879,
          0.02209323746126317,
          0.025542700975322873,
          0.02559893166563769,
          0.026575212817247448,
          0.027730687462900114,
          0.028014375170701815,
          0.031616018789628386,
          0.036219170535060755,
          0.038131333126062074,
          0.056972129046208644,
          0.07169756523163816,
          0.07861381065229754,
          0.12972589668605977
         ],
         "y": [
          "ps_ind_10_bin",
          "ps_ind_11_bin",
          "ps_ind_13_bin",
          "ps_calc_20_bin",
          "ps_ind_12_bin",
          "ps_calc_15_bin",
          "ps_car_10_cat",
          "ps_ind_18_bin",
          "ps_calc_16_bin",
          "ps_ind_14",
          "ps_calc_18_bin",
          "ps_calc_17_bin",
          "ps_calc_19_bin",
          "ps_car_08_cat",
          "ps_ind_09_bin",
          "ps_ind_08_bin",
          "ps_car_11",
          "ps_car_05_cat",
          "ps_calc_04",
          "ps_calc_06",
          "ps_car_09_cat",
          "ps_car_02_cat",
          "ps_calc_09",
          "ps_calc_12",
          "ps_calc_08",
          "ps_calc_05",
          "ps_ind_02_cat",
          "ps_calc_07",
          "ps_calc_03",
          "ps_calc_13",
          "ps_calc_01",
          "ps_calc_02",
          "ps_car_06_cat",
          "ps_ind_16_bin",
          "ps_calc_11",
          "ps_reg_01",
          "ps_ind_01",
          "ps_car_11_cat",
          "ps_calc_14",
          "ps_car_15",
          "ps_calc_10",
          "ps_ind_04_cat",
          "ps_ind_06_bin",
          "ps_car_03_cat",
          "ps_ind_07_bin",
          "ps_car_01_cat",
          "ps_ind_15",
          "ps_car_12",
          "ps_car_14",
          "ps_car_04_cat",
          "ps_car_07_cat",
          "ps_ind_03",
          "ps_reg_02",
          "ps_ind_17_bin",
          "ps_reg_03",
          "ps_ind_05_cat",
          "ps_car_13"
         ]
        }
       ],
       "layout": {
        "height": 2000,
        "title": "Barplot of Feature importances",
        "width": 900,
        "yaxis": {
         "showgrid": false,
         "showline": false,
         "showticklabels": true
        }
       }
      },
      "text/html": [
       "<div id=\"f4c3797b-7a64-4286-a54f-964b47771633\" style=\"height: 2000px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f4c3797b-7a64-4286-a54f-964b47771633\", [{\"x\": [0.0003743181308508165, 0.000658587568488969, 0.0006631273358967262, 0.0012870902040590282, 0.0013468714834950239, 0.001870133874931154, 0.001989572452739753, 0.002157913151265299, 0.002257450267841548, 0.002396248137555366, 0.0024558305914006385, 0.002469687345810993, 0.0026302488825493274, 0.0033942424985942323, 0.003607748989459628, 0.004198705181889577, 0.006131305051533334, 0.006161484578645829, 0.008128745850432492, 0.00859806923363534, 0.00931835490969756, 0.009404375939580238, 0.00976021723144253, 0.010077793671110571, 0.01014094472565096, 0.010594230122584794, 0.011053805247045436, 0.011555325103106582, 0.011576231652990453, 0.011709915331607012, 0.012009756930235212, 0.012160372455969666, 0.013635548698960633, 0.013920353817181067, 0.015948843121933284, 0.016475991648979886, 0.01686434542269142, 0.0169000533930654, 0.01718398425858274, 0.018552997743760267, 0.019068010059436213, 0.019470566624956092, 0.019871398042689628, 0.02143813341563879, 0.02209323746126317, 0.025542700975322873, 0.02559893166563769, 0.026575212817247448, 0.027730687462900114, 0.028014375170701815, 0.031616018789628386, 0.036219170535060755, 0.038131333126062074, 0.056972129046208644, 0.07169756523163816, 0.07861381065229754, 0.12972589668605977], \"name\": \"Random Forest Feature importance\", \"marker\": {\"colorscale\": \"Viridis\", \"color\": [0.0003743181308508165, 0.000658587568488969, 0.0006631273358967262, 0.0012870902040590282, 0.0013468714834950239, 0.001870133874931154, 0.001989572452739753, 0.002157913151265299, 0.002257450267841548, 0.002396248137555366, 0.0024558305914006385, 0.002469687345810993, 0.0026302488825493274, 0.0033942424985942323, 0.003607748989459628, 0.004198705181889577, 0.006131305051533334, 0.006161484578645829, 0.008128745850432492, 0.00859806923363534, 0.00931835490969756, 0.009404375939580238, 0.00976021723144253, 0.010077793671110571, 0.01014094472565096, 0.010594230122584794, 0.011053805247045436, 0.011555325103106582, 0.011576231652990453, 0.011709915331607012, 0.012009756930235212, 0.012160372455969666, 0.013635548698960633, 0.013920353817181067, 0.015948843121933284, 0.016475991648979886, 0.01686434542269142, 0.0169000533930654, 0.01718398425858274, 0.018552997743760267, 0.019068010059436213, 0.019470566624956092, 0.019871398042689628, 0.02143813341563879, 0.02209323746126317, 0.025542700975322873, 0.02559893166563769, 0.026575212817247448, 0.027730687462900114, 0.028014375170701815, 0.031616018789628386, 0.036219170535060755, 0.038131333126062074, 0.056972129046208644, 0.07169756523163816, 0.07861381065229754, 0.12972589668605977], \"reversescale\": true}, \"orientation\": \"h\", \"y\": [\"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_13_bin\", \"ps_calc_20_bin\", \"ps_ind_12_bin\", \"ps_calc_15_bin\", \"ps_car_10_cat\", \"ps_ind_18_bin\", \"ps_calc_16_bin\", \"ps_ind_14\", \"ps_calc_18_bin\", \"ps_calc_17_bin\", \"ps_calc_19_bin\", \"ps_car_08_cat\", \"ps_ind_09_bin\", \"ps_ind_08_bin\", \"ps_car_11\", \"ps_car_05_cat\", \"ps_calc_04\", \"ps_calc_06\", \"ps_car_09_cat\", \"ps_car_02_cat\", \"ps_calc_09\", \"ps_calc_12\", \"ps_calc_08\", \"ps_calc_05\", \"ps_ind_02_cat\", \"ps_calc_07\", \"ps_calc_03\", \"ps_calc_13\", \"ps_calc_01\", \"ps_calc_02\", \"ps_car_06_cat\", \"ps_ind_16_bin\", \"ps_calc_11\", \"ps_reg_01\", \"ps_ind_01\", \"ps_car_11_cat\", \"ps_calc_14\", \"ps_car_15\", \"ps_calc_10\", \"ps_ind_04_cat\", \"ps_ind_06_bin\", \"ps_car_03_cat\", \"ps_ind_07_bin\", \"ps_car_01_cat\", \"ps_ind_15\", \"ps_car_12\", \"ps_car_14\", \"ps_car_04_cat\", \"ps_car_07_cat\", \"ps_ind_03\", \"ps_reg_02\", \"ps_ind_17_bin\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_car_13\"], \"type\": \"bar\"}], {\"height\": 2000, \"yaxis\": {\"showticklabels\": true, \"showgrid\": false, \"showline\": false}, \"title\": \"Barplot of Feature importances\", \"width\": 900}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"f4c3797b-7a64-4286-a54f-964b47771633\" style=\"height: 2000px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f4c3797b-7a64-4286-a54f-964b47771633\", [{\"x\": [0.0003743181308508165, 0.000658587568488969, 0.0006631273358967262, 0.0012870902040590282, 0.0013468714834950239, 0.001870133874931154, 0.001989572452739753, 0.002157913151265299, 0.002257450267841548, 0.002396248137555366, 0.0024558305914006385, 0.002469687345810993, 0.0026302488825493274, 0.0033942424985942323, 0.003607748989459628, 0.004198705181889577, 0.006131305051533334, 0.006161484578645829, 0.008128745850432492, 0.00859806923363534, 0.00931835490969756, 0.009404375939580238, 0.00976021723144253, 0.010077793671110571, 0.01014094472565096, 0.010594230122584794, 0.011053805247045436, 0.011555325103106582, 0.011576231652990453, 0.011709915331607012, 0.012009756930235212, 0.012160372455969666, 0.013635548698960633, 0.013920353817181067, 0.015948843121933284, 0.016475991648979886, 0.01686434542269142, 0.0169000533930654, 0.01718398425858274, 0.018552997743760267, 0.019068010059436213, 0.019470566624956092, 0.019871398042689628, 0.02143813341563879, 0.02209323746126317, 0.025542700975322873, 0.02559893166563769, 0.026575212817247448, 0.027730687462900114, 0.028014375170701815, 0.031616018789628386, 0.036219170535060755, 0.038131333126062074, 0.056972129046208644, 0.07169756523163816, 0.07861381065229754, 0.12972589668605977], \"name\": \"Random Forest Feature importance\", \"marker\": {\"colorscale\": \"Viridis\", \"color\": [0.0003743181308508165, 0.000658587568488969, 0.0006631273358967262, 0.0012870902040590282, 0.0013468714834950239, 0.001870133874931154, 0.001989572452739753, 0.002157913151265299, 0.002257450267841548, 0.002396248137555366, 0.0024558305914006385, 0.002469687345810993, 0.0026302488825493274, 0.0033942424985942323, 0.003607748989459628, 0.004198705181889577, 0.006131305051533334, 0.006161484578645829, 0.008128745850432492, 0.00859806923363534, 0.00931835490969756, 0.009404375939580238, 0.00976021723144253, 0.010077793671110571, 0.01014094472565096, 0.010594230122584794, 0.011053805247045436, 0.011555325103106582, 0.011576231652990453, 0.011709915331607012, 0.012009756930235212, 0.012160372455969666, 0.013635548698960633, 0.013920353817181067, 0.015948843121933284, 0.016475991648979886, 0.01686434542269142, 0.0169000533930654, 0.01718398425858274, 0.018552997743760267, 0.019068010059436213, 0.019470566624956092, 0.019871398042689628, 0.02143813341563879, 0.02209323746126317, 0.025542700975322873, 0.02559893166563769, 0.026575212817247448, 0.027730687462900114, 0.028014375170701815, 0.031616018789628386, 0.036219170535060755, 0.038131333126062074, 0.056972129046208644, 0.07169756523163816, 0.07861381065229754, 0.12972589668605977], \"reversescale\": true}, \"orientation\": \"h\", \"y\": [\"ps_ind_10_bin\", \"ps_ind_11_bin\", \"ps_ind_13_bin\", \"ps_calc_20_bin\", \"ps_ind_12_bin\", \"ps_calc_15_bin\", \"ps_car_10_cat\", \"ps_ind_18_bin\", \"ps_calc_16_bin\", \"ps_ind_14\", \"ps_calc_18_bin\", \"ps_calc_17_bin\", \"ps_calc_19_bin\", \"ps_car_08_cat\", \"ps_ind_09_bin\", \"ps_ind_08_bin\", \"ps_car_11\", \"ps_car_05_cat\", \"ps_calc_04\", \"ps_calc_06\", \"ps_car_09_cat\", \"ps_car_02_cat\", \"ps_calc_09\", \"ps_calc_12\", \"ps_calc_08\", \"ps_calc_05\", \"ps_ind_02_cat\", \"ps_calc_07\", \"ps_calc_03\", \"ps_calc_13\", \"ps_calc_01\", \"ps_calc_02\", \"ps_car_06_cat\", \"ps_ind_16_bin\", \"ps_calc_11\", \"ps_reg_01\", \"ps_ind_01\", \"ps_car_11_cat\", \"ps_calc_14\", \"ps_car_15\", \"ps_calc_10\", \"ps_ind_04_cat\", \"ps_ind_06_bin\", \"ps_car_03_cat\", \"ps_ind_07_bin\", \"ps_car_01_cat\", \"ps_ind_15\", \"ps_car_12\", \"ps_car_14\", \"ps_car_04_cat\", \"ps_car_07_cat\", \"ps_ind_03\", \"ps_reg_02\", \"ps_ind_17_bin\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_car_13\"], \"type\": \"bar\"}], {\"height\": 2000, \"yaxis\": {\"showticklabels\": true, \"showgrid\": false, \"showline\": false}, \"title\": \"Barplot of Feature importances\", \"width\": 900}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = (list(x) for x in zip(*sorted(zip(rf.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "trace2 = go.Bar(\n",
    "    x=x ,\n",
    "    y=y,\n",
    "    marker=dict(\n",
    "        color=x,\n",
    "        colorscale = 'Viridis',\n",
    "        reversescale = True\n",
    "    ),\n",
    "    name='Random Forest Feature importance',\n",
    "    orientation='h',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Barplot of Feature importances',\n",
    "     width = 900, height = 2000,\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "#         domain=[0, 0.85],\n",
    "    ))\n",
    "\n",
    "fig1 = go.Figure(data=[trace2])\n",
    "fig1['layout'].update(layout)\n",
    "py.iplot(fig1, filename='plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/ogrellier/feature-selection-target-permutations there is alternative eda to check on feature importance\n",
    "trn_df = pd.read_csv(\"train.csv\", index_col=0)\n",
    "target = trn_df.target\n",
    "del trn_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(boosting_type=\"rf\",\n",
    "                     num_leaves=1024,\n",
    "                     max_depth=6,\n",
    "                     n_estimators=500, \n",
    "                     subsample=.632,\n",
    "                     colsample_bytree=.5,\n",
    "                     n_jobs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0 OOF score : 0.009595\n",
      "Run  1 OOF score : 0.002024\n",
      "Run  2 OOF score : -0.005417\n",
      "Run  3 OOF score : 0.000546\n",
      "Run  4 OOF score : -0.001377\n"
     ]
    }
   ],
   "source": [
    "n_splits = 2\n",
    "n_runs = 5\n",
    "imp_df = np.zeros((len(trn_df.columns), n_splits * n_runs))\n",
    "np.random.seed(9385610)\n",
    "idx = np.arange(len(target))\n",
    "for run in range(n_runs):\n",
    "    # Shuffle target\n",
    "    np.random.shuffle(idx)\n",
    "    perm_target = target.iloc[idx]\n",
    "    # Create a new split\n",
    "    folds = StratifiedKFold(n_splits, True, None)\n",
    "    oof = np.empty(len(trn_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(perm_target, perm_target)):\n",
    "        trn_dat, trn_tgt = trn_df.iloc[trn_idx], perm_target.iloc[trn_idx]\n",
    "        val_dat, val_tgt = trn_df.iloc[val_idx], perm_target.iloc[val_idx]\n",
    "        # Train classifier\n",
    "        clf.fit(trn_dat, trn_tgt)\n",
    "        # Keep feature importances for this fold and run\n",
    "        imp_df[:, n_splits * run + fold_] = clf.feature_importances_\n",
    "        # Update OOF for gini score display\n",
    "        oof[val_idx] = clf.predict_proba(val_dat)[:, 1]\n",
    "        \n",
    "    print(\"Run %2d OOF score : %.6f\" % (run, eval_gini(perm_target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0 OOF score : 0.257034\n",
      "Run  1 OOF score : 0.258336\n",
      "Run  2 OOF score : 0.256461\n",
      "Run  3 OOF score : 0.254122\n",
      "Run  4 OOF score : 0.255370\n"
     ]
    }
   ],
   "source": [
    "bench_imp_df = np.zeros((len(trn_df.columns), n_splits * n_runs))\n",
    "for run in range(n_runs):\n",
    "    # Shuffle target AND dataset\n",
    "    np.random.shuffle(idx)\n",
    "    perm_target = target.iloc[idx]\n",
    "    perm_data = trn_df.iloc[idx]\n",
    "    \n",
    "    # Create a new split\n",
    "    folds = StratifiedKFold(n_splits, True, None)\n",
    "    oof = np.empty(len(trn_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(perm_target, perm_target)):\n",
    "        trn_dat, trn_tgt = perm_data.iloc[trn_idx], perm_target.iloc[trn_idx]\n",
    "        val_dat, val_tgt = perm_data.iloc[val_idx], perm_target.iloc[val_idx]\n",
    "        # Train classifier\n",
    "        clf.fit(trn_dat, trn_tgt)\n",
    "        # Keep feature importances for this fold and run\n",
    "        bench_imp_df[:, n_splits * run + fold_] = clf.feature_importances_\n",
    "        # Update OOF for gini score display\n",
    "        oof[val_idx] = clf.predict_proba(val_dat)[:, 1]\n",
    "        \n",
    "    print(\"Run %2d OOF score : %.6f\" % (run, eval_gini(perm_target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature              | benchmark | permutation | Ratio\n",
      "ps_ind_17_bin        |     617.7 |        96.6 |       6.4\n",
      "ps_car_07_cat        |     835.1 |       143.1 |       5.8\n",
      "ps_ind_05_cat        |    1529.9 |       266.6 |       5.7\n",
      "ps_ind_07_bin        |     524.3 |       113.8 |       4.6\n",
      "ps_ind_16_bin        |     515.0 |       113.2 |       4.5\n",
      "ps_car_03_cat        |     751.0 |       179.4 |       4.2\n",
      "ps_ind_06_bin        |     385.2 |       110.1 |       3.5\n",
      "ps_car_02_cat        |     225.3 |        83.0 |       2.7\n",
      "ps_car_04_cat        |     403.0 |       183.2 |       2.2\n",
      "ps_car_08_cat        |     155.8 |        71.3 |       2.2\n",
      "ps_ind_03            |    1476.6 |       733.7 |       2.0\n",
      "ps_ind_08_bin        |     177.7 |        93.6 |       1.9\n",
      "ps_car_01_cat        |     982.8 |       552.3 |       1.8\n",
      "ps_reg_02            |    1226.7 |       726.7 |       1.7\n",
      "ps_ind_15            |    1315.3 |       794.6 |       1.7\n",
      "ps_ind_01            |     793.8 |       482.7 |       1.6\n",
      "ps_reg_01            |     857.5 |       535.6 |       1.6\n",
      "ps_ind_09_bin        |     141.5 |        94.1 |       1.5\n",
      "ps_car_11            |     319.9 |       237.6 |       1.3\n",
      "ps_ind_04_cat        |     174.7 |       130.3 |       1.3\n",
      "ps_car_13            |    2194.3 |      1698.6 |       1.3\n",
      "ps_car_05_cat        |     253.9 |       196.6 |       1.3\n",
      "ps_car_15            |     869.9 |       691.8 |       1.3\n",
      "ps_reg_03            |    1628.4 |      1306.8 |       1.2\n",
      "ps_ind_12_bin        |      53.7 |        45.1 |       1.2\n",
      "ps_car_12            |     911.6 |       789.7 |       1.2\n",
      "ps_car_09_cat        |     325.8 |       287.8 |       1.1\n",
      "ps_ind_18_bin        |      99.0 |        91.0 |       1.1\n",
      "ps_car_06_cat        |     610.5 |       591.0 |       1.0\n",
      "ps_ind_02_cat        |     223.7 |       218.5 |       1.0\n",
      "ps_car_14            |    1188.5 |      1267.2 |       0.9\n",
      "ps_ind_14            |      52.3 |        65.5 |       0.8\n",
      "ps_calc_09           |     313.5 |       432.9 |       0.7\n",
      "ps_calc_12           |     336.1 |       467.8 |       0.7\n",
      "ps_calc_05           |     280.7 |       413.0 |       0.7\n",
      "ps_calc_02           |     381.4 |       568.7 |       0.7\n",
      "ps_calc_01           |     423.6 |       638.4 |       0.7\n",
      "ps_calc_03           |     401.7 |       622.6 |       0.6\n",
      "ps_car_11_cat        |     675.4 |      1062.7 |       0.6\n",
      "ps_calc_08           |     349.3 |       551.5 |       0.6\n",
      "ps_calc_10           |     553.7 |       881.7 |       0.6\n",
      "ps_calc_17_bin       |      90.4 |       144.3 |       0.6\n",
      "ps_calc_04           |     263.8 |       422.3 |       0.6\n",
      "ps_car_10_cat        |      47.8 |        77.1 |       0.6\n",
      "ps_calc_11           |     479.9 |       778.1 |       0.6\n",
      "ps_calc_07           |     344.4 |       558.5 |       0.6\n",
      "ps_calc_14           |     508.4 |       854.3 |       0.6\n",
      "ps_calc_16_bin       |      72.0 |       122.1 |       0.6\n",
      "ps_calc_19_bin       |      81.1 |       137.7 |       0.6\n",
      "ps_calc_13           |     353.8 |       622.1 |       0.6\n",
      "ps_calc_06           |     296.6 |       523.2 |       0.6\n",
      "ps_calc_18_bin       |      69.6 |       126.5 |       0.6\n",
      "ps_calc_15_bin       |      46.1 |        93.0 |       0.5\n",
      "ps_calc_20_bin       |      42.6 |       106.9 |       0.4\n",
      "ps_ind_13_bin        |       1.5 |        10.1 |       0.1\n",
      "ps_ind_11_bin        |       4.6 |        44.4 |       0.1\n",
      "ps_ind_10_bin        |       0.3 |         6.7 |       0.0\n"
     ]
    }
   ],
   "source": [
    "bench_mean = bench_imp_df.mean(axis=1)\n",
    "perm_mean = imp_df.mean(axis=1)\n",
    "\n",
    "values = []\n",
    "for i, f in enumerate(trn_df.columns):\n",
    "    values.append((f, bench_mean[i], perm_mean[i], bench_mean[i] / perm_mean[i]))\n",
    "\n",
    "print(\"%-20s | benchmark | permutation | Ratio\" % \"Feature\")\n",
    "values = sorted(values, key=lambda x: x[3])\n",
    "for f, b, p, r in values[::-1]:\n",
    "    print(\"%-20s |   %7.1f |     %7.1f |   %7.1f\" \n",
    "          % (f, b, p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: test-train splitter:\n",
    "For a project list this, it's better to do your own train test split before a 5 fold CV: 5 fold CV grid search with some of these models (like xgboost), is computationally very expensive. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "ssX = train.drop(['id','target'],axis=1)\n",
    "ssy = train['target']\n",
    "train_x_fe=ssX\n",
    "train_y=ssy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_train_x, train_test_x, train_train_y, train_test_y = train_test_split(ssX, ssy, test_size=0.2, stratify=ssy, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a process from a kaggle kernel, to explain, we are using some randomized attemts at classifiers to find what are the most import features.\n",
    "# we can then create new features by combining two of the most important features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# feature engineering workflow:\n",
    "ps_ind_13_bin  \n",
    "ps_ind_12_bin  \n",
    "ps_ind_11_bin        \n",
    "ps_ind_10_bin\n",
    "ps_ind_calc_20\n",
    "ps_ind_cal_15\n",
    "produce so little value the features should be dropped (any feature not contributing is liekly random noise, and gives the model a chance to overfit)\n",
    "\n",
    "So the next question is how to engineer new  features? \n",
    "the binaries of 17,16,7,6 all add value, so we'll add a feature that is the sum of those 4 columns. \n",
    "\n",
    "PS car_13 and ps_reg 03 seem to be important, so we'll add them as a feature, and multiply them as a feature. \n",
    "\n",
    "car 13 squared, \n",
    "\n",
    "reg 03 squared\n",
    "\n",
    "car 14, car 12 , ind 15 sum\n",
    "\n",
    "car 14, car 12 ind 15 multiplied as a feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping nonvalued data\n",
    "test_fe = test.drop(['ps_ind_13_bin','ps_ind_12_bin', 'ps_ind_11_bin','ps_ind_10_bin','ps_calc_20_bin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   0          0              1          8              1              0   \n",
       "1   1          4              2          5              1              0   \n",
       "2   2          5              1          3              0              0   \n",
       "3   3          0              1          6              0              0   \n",
       "4   4          5              1          7              0              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin       ...        \\\n",
       "0              0              1              0              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              1              0              0              0       ...         \n",
       "4              0              0              0              1       ...         \n",
       "\n",
       "   ps_calc_10  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           1           1          12               0   \n",
       "1           7           2           0           3          10               0   \n",
       "2          12           4           0           2           4               0   \n",
       "3          13           5           1           0           5               1   \n",
       "4          12           4           0           0           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \n",
       "0               1               1               0               0  \n",
       "1               0               1               1               0  \n",
       "2               0               0               0               0  \n",
       "3               0               1               0               0  \n",
       "4               1               1               0               0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_train_x_fe= train_train_x.drop(['ps_ind_13_bin','ps_ind_12_bin', 'ps_ind_11_bin','ps_ind_10_bin','ps_calc_20_bin'],axis=1)\n",
    "train_test_x_fe= train_test_x.drop(['ps_ind_13_bin','ps_ind_12_bin', 'ps_ind_11_bin','ps_ind_10_bin','ps_calc_20_bin'],axis=1)\n",
    "train_x_fe= train_x_fe.drop(['ps_ind_13_bin','ps_ind_12_bin', 'ps_ind_11_bin','ps_ind_10_bin','ps_calc_20_bin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#binary sums\n",
    "test_fe['binary_sums_17_16_7_6']=test_fe['ps_ind_17_bin']+test_fe['ps_ind_16_bin']+test_fe['ps_ind_07_bin']+test_fe['ps_ind_06_bin']\n",
    "train_test_x_fe['binary_sums_17_16_7_6']=train_test_x_fe['ps_ind_17_bin']+train_test_x_fe['ps_ind_16_bin']+train_test_x_fe['ps_ind_07_bin']+train_test_x_fe['ps_ind_06_bin']\n",
    "train_train_x_fe['binary_sums_17_16_7_6']=train_train_x_fe['ps_ind_17_bin']+train_train_x_fe['ps_ind_16_bin']+train_train_x_fe['ps_ind_07_bin']+train_train_x_fe['ps_ind_06_bin']\n",
    "train_x_fe['binary_sums_17_16_7_6']=train_x_fe['ps_ind_17_bin']+train_x_fe['ps_ind_16_bin']+train_x_fe['ps_ind_07_bin']+train_x_fe['ps_ind_06_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#car_13, reg03 sum\n",
    "test_fe['sum_car_13_reg03']= test_fe['ps_car_13']+test_fe['ps_reg_03']\n",
    "train_train_x_fe['sum_car_13_reg03']= train_train_x_fe['ps_car_13']+train_train_x_fe['ps_reg_03']\n",
    "train_test_x_fe['sum_car_13_reg03']= train_test_x_fe['ps_car_13']+train_test_x_fe['ps_reg_03']\n",
    "train_x_fe['sum_car_13_reg03']= train_x_fe['ps_car_13']+train_x_fe['ps_reg_03']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#car_13, reg03 mult\n",
    "test_fe['mult_car_13_reg03']= test_fe['ps_car_13']*test_fe['ps_reg_03']\n",
    "train_train_x_fe['mult_car_13_reg03']= train_train_x_fe['ps_car_13']*train_train_x_fe['ps_reg_03']\n",
    "train_test_x_fe['mult_car_13_reg03']= train_test_x_fe['ps_car_13']*train_test_x_fe['ps_reg_03']\n",
    "train_x_fe['mult_car_13_reg03']= train_x_fe['ps_car_13']*train_x_fe['ps_reg_03']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#car_13 sq\n",
    "test_fe['sq_car_13']= test_fe['ps_car_13']*test_fe['ps_car_13']\n",
    "train_train_x_fe['sq_car_13']= train_train_x_fe['ps_car_13']*train_train_x_fe['ps_car_13']\n",
    "train_test_x_fe['sq_car_13']= train_test_x_fe['ps_car_13']*train_test_x_fe['ps_car_13']\n",
    "train_x_fe['sq_car_13']= train_x_fe['ps_car_13']*train_x_fe['ps_car_13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reg03 sq\n",
    "test_fe['sq_reg03']= test_fe['ps_car_13']*test_fe['ps_reg_03']\n",
    "train_train_x_fe['sq_reg03']= train_train_x_fe['ps_reg_03']*train_train_x_fe['ps_reg_03']\n",
    "train_test_x_fe['sq_reg03']= train_test_x_fe['ps_reg_03']*train_test_x_fe['ps_reg_03']\n",
    "train_x_fe['sq_reg03']= train_x_fe['ps_reg_03']*train_x_fe['ps_reg_03']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#car 14, car 12 , ind 15 sum\n",
    "test_fe['sum_car14_car12_ind15']= test_fe['ps_car_14']+test_fe['ps_car_12']+test_fe['ps_ind_15']\n",
    "train_test_x_fe['sum_car14_car12_ind15']= train_test_x_fe['ps_car_14']+train_test_x_fe['ps_car_12']+train_test_x_fe['ps_ind_15']\n",
    "train_train_x_fe['sum_car14_car12_ind15']= train_train_x_fe['ps_car_14']+train_train_x_fe['ps_car_12']+train_train_x_fe['ps_ind_15']\n",
    "train_x_fe['sum_car14_car12_ind15']= train_x_fe['ps_car_14']+train_x_fe['ps_car_12']+train_x_fe['ps_ind_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#car 14, car 12 , ind 15 mult\n",
    "test_fe['mult_car14_car12_ind15']= test_fe['ps_car_14']*test_fe['ps_car_12']*test_fe['ps_ind_15']\n",
    "train_test_x_fe['mult_car14_car12_ind15']= train_test_x_fe['ps_car_14']*train_test_x_fe['ps_car_12']*train_test_x_fe['ps_ind_15']\n",
    "train_train_x_fe['mult_car14_car12_ind15']= train_train_x_fe['ps_car_14']*train_train_x_fe['ps_car_12']*train_train_x_fe['ps_ind_15']\n",
    "train_x_fe['mult_car14_car12_ind15']= train_x_fe['ps_car_14']*train_x_fe['ps_car_12']*train_x_fe['ps_ind_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next:\n",
    "The project bifurcates here. \n",
    "The final 'production' result is going to be an absurd ensemble:\n",
    "https://www.kaggle.com/zusmani/lgb-esemble-xgb-be-in-top-100-with-lb-0-285/output\n",
    "has acceptably clean code for this. \n",
    "So I can save out my train and test feature engineering and run that code. \n",
    "\n",
    "The rest of this notebook is for hyperparameter optimization for each of the component models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5: Xgboost hyperparameter tuning\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "explain what I'm doing here, in short, lets find the best hyperparameters for xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'binary_sums_17_16_7_6', 'sum_car_13_reg03', 'mult_car_13_reg03',\n",
       "       'sq_car_13', 'sq_reg03', 'sum_car14_car12_ind15',\n",
       "       'mult_car14_car12_ind15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "# Create an XGBoost-compatible metric from Gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score\n",
    "    \n",
    "\n",
    "xgbscores = []\n",
    "\n",
    "# Set xgb parameters\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.03\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 8\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.85\n",
    "params['colsample_bylevel'] = 0.9\n",
    "#params['tree_method'] = 'exact'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to find how many trees. \n",
    "I'm not going to use crossval, simply due to computational expense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-gini:0.230157\tvalid-gini:0.214863\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 70 rounds.\n",
      "[100]\ttrain-gini:0.362429\tvalid-gini:0.261215\n",
      "[200]\ttrain-gini:0.481147\tvalid-gini:0.27294\n",
      "[300]\ttrain-gini:0.57091\tvalid-gini:0.276014\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-gini:0.575042\tvalid-gini:0.276217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.025\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 8\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.85\n",
    "params['colsample_bylevel'] = 0.9\n",
    "d_train = xgb.DMatrix(train_train_x_fe, train_train_y)\n",
    "d_valid = xgb.DMatrix(train_test_x_fe, train_test_y)\n",
    "d_final_test = xgb.DMatrix(train_x_fe, label=train_y)\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gini_scorer = metrics.make_scorer(gini_normalized, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f99d9b74a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgsearch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m322\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_test1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgini_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_fe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    443\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "param_test1 = {}\n",
    "param_test1['max_depth']=[3,5,6,8,10]\n",
    "param_test1['min_child_weight']=[.5,.75,2]\n",
    "\n",
    "param_test1['objective'] = ['binary:logistic']\n",
    "#param_test1['eta'] = [0.03]\n",
    "param_test1['silent'] = [True]\n",
    "param_test1['subsample'] = [.8]\n",
    "param_test1['colsample_bytree'] = [0.85]\n",
    "param_test1['colsample_bylevel'] = [0.9]\n",
    "param_test1['scale_pos_weight'] = [1.6]\n",
    "param_test1['n_estimators']=[306]\n",
    "param_test1['learning_rate']=[.025]\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(n_estimators=322,nthread=-1), param_grid = param_test1,iid=False,scoring = gini_scorer, cv=5)\n",
    "gsearch1.fit(train_x_fe,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "param_test1 = {}\n",
    "param_test1['max_depth']=[6,8,10]\n",
    "param_test1['min_child_weight']=[.5,2]\n",
    "\n",
    "param_test1['objective'] = ['binary:logistic']\n",
    "#param_test1['eta'] = [0.03]\n",
    "param_test1['silent'] = [True]\n",
    "param_test1['subsample'] = [.8]\n",
    "param_test1['colsample_bytree'] = [0.85]\n",
    "param_test1['colsample_bylevel'] = [0.9]\n",
    "param_test1['scale_pos_weight'] = [1.6]\n",
    "param_test1['n_estimators']=[306]\n",
    "param_test1['learning_rate']=[.025]\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(n_estimators=322,nthread=-1), param_grid = param_test1,iid=False,scoring = 'roc_auc', cv=3)\n",
    "gsearch1.fit(train_x_fe,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.63883, std: 0.00084, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 0.5, 'learning_rate': 0.025, 'max_depth': 6, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85},\n",
       " mean: 0.63903, std: 0.00071, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 2, 'learning_rate': 0.025, 'max_depth': 6, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85},\n",
       " mean: 0.63692, std: 0.00072, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 0.5, 'learning_rate': 0.025, 'max_depth': 8, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85},\n",
       " mean: 0.63717, std: 0.00097, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 2, 'learning_rate': 0.025, 'max_depth': 8, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85},\n",
       " mean: 0.63247, std: 0.00121, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 0.5, 'learning_rate': 0.025, 'max_depth': 10, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85},\n",
       " mean: 0.63272, std: 0.00068, params: {'objective': 'binary:logistic', 'scale_pos_weight': 1.6, 'colsample_bylevel': 0.9, 'silent': True, 'min_child_weight': 2, 'learning_rate': 0.025, 'max_depth': 10, 'n_estimators': 306, 'subsample': 0.8, 'colsample_bytree': 0.85}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.9,\n",
       " 'colsample_bytree': 0.85,\n",
       " 'learning_rate': 0.025,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 306,\n",
       " 'objective': 'binary:logistic',\n",
       " 'scale_pos_weight': 1.6,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6390312496524134"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(gsearch1.predict(train_x_fe),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Catboost+Parameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borders for float features generated\n",
      "0:\tlearn 0.5328927227\ttest 0.5305296051\tbestTest 0.5305296051\t\ttotal: 661ms\tremaining: 13m 12s\n",
      "1:\tlearn 0.5913348968\ttest 0.5887532093\tbestTest 0.5887532093\t\ttotal: 1.29s\tremaining: 12m 53s\n",
      "2:\tlearn 0.5932298814\ttest 0.5902804054\tbestTest 0.5902804054\t\ttotal: 1.91s\tremaining: 12m 40s\n",
      "3:\tlearn 0.596211205\ttest 0.5928300364\tbestTest 0.5928300364\t\ttotal: 2.54s\tremaining: 12m 38s\n",
      "4:\tlearn 0.5973418459\ttest 0.5933124006\tbestTest 0.5933124006\t\ttotal: 3.14s\tremaining: 12m 31s\n",
      "5:\tlearn 0.5991870177\ttest 0.5941255068\tbestTest 0.5941255068\t\ttotal: 3.84s\tremaining: 12m 45s\n",
      "6:\tlearn 0.598259185\ttest 0.5914457123\tbestTest 0.5941255068\t\ttotal: 4.5s\tremaining: 12m 47s\n",
      "7:\tlearn 0.6009381574\ttest 0.5926909809\tbestTest 0.5941255068\t\ttotal: 5.18s\tremaining: 12m 51s\n",
      "8:\tlearn 0.6014148894\ttest 0.5943446144\tbestTest 0.5943446144\t\ttotal: 5.83s\tremaining: 12m 51s\n",
      "9:\tlearn 0.6046120299\ttest 0.5984664796\tbestTest 0.5984664796\t\ttotal: 6.54s\tremaining: 12m 57s\n",
      "10:\tlearn 0.6065046598\ttest 0.6011543192\tbestTest 0.6011543192\t\ttotal: 7.18s\tremaining: 12m 56s\n",
      "11:\tlearn 0.611407283\ttest 0.605239359\tbestTest 0.605239359\t\ttotal: 7.84s\tremaining: 12m 56s\n",
      "12:\tlearn 0.6123700631\ttest 0.6059562166\tbestTest 0.6059562166\t\ttotal: 8.48s\tremaining: 12m 54s\n",
      "13:\tlearn 0.6114354191\ttest 0.6057014992\tbestTest 0.6059562166\t\ttotal: 9.13s\tremaining: 12m 53s\n",
      "14:\tlearn 0.6138458366\ttest 0.607380182\tbestTest 0.607380182\t\ttotal: 9.79s\tremaining: 12m 53s\n",
      "15:\tlearn 0.6155640052\ttest 0.6081566487\tbestTest 0.6081566487\t\ttotal: 10.4s\tremaining: 12m 52s\n",
      "16:\tlearn 0.615415433\ttest 0.6069158567\tbestTest 0.6081566487\t\ttotal: 11.1s\tremaining: 12m 49s\n",
      "17:\tlearn 0.6177041238\ttest 0.6088991854\tbestTest 0.6088991854\t\ttotal: 11.7s\tremaining: 12m 47s\n",
      "18:\tlearn 0.618436346\ttest 0.6104148153\tbestTest 0.6104148153\t\ttotal: 12.4s\tremaining: 12m 50s\n",
      "19:\tlearn 0.620265489\ttest 0.6120018234\tbestTest 0.6120018234\t\ttotal: 13s\tremaining: 12m 49s\n",
      "20:\tlearn 0.620519203\ttest 0.611890833\tbestTest 0.6120018234\t\ttotal: 13.7s\tremaining: 12m 48s\n",
      "21:\tlearn 0.6210703743\ttest 0.6126746194\tbestTest 0.6126746194\t\ttotal: 14.3s\tremaining: 12m 46s\n",
      "22:\tlearn 0.6204459574\ttest 0.612477525\tbestTest 0.6126746194\t\ttotal: 15s\tremaining: 12m 45s\n",
      "23:\tlearn 0.6204959898\ttest 0.6128708056\tbestTest 0.6128708056\t\ttotal: 15.6s\tremaining: 12m 44s\n",
      "24:\tlearn 0.6214801961\ttest 0.6136278229\tbestTest 0.6136278229\t\ttotal: 16.3s\tremaining: 12m 45s\n",
      "25:\tlearn 0.6215650719\ttest 0.6134353839\tbestTest 0.6136278229\t\ttotal: 16.9s\tremaining: 12m 44s\n",
      "26:\tlearn 0.6219378162\ttest 0.6134450082\tbestTest 0.6136278229\t\ttotal: 17.6s\tremaining: 12m 43s\n",
      "27:\tlearn 0.621979629\ttest 0.613317094\tbestTest 0.6136278229\t\ttotal: 18.2s\tremaining: 12m 43s\n",
      "28:\tlearn 0.6228647918\ttest 0.614245841\tbestTest 0.614245841\t\ttotal: 18.8s\tremaining: 12m 40s\n",
      "29:\tlearn 0.6233951356\ttest 0.6148751007\tbestTest 0.6148751007\t\ttotal: 19.4s\tremaining: 12m 36s\n",
      "30:\tlearn 0.6244081747\ttest 0.6154484735\tbestTest 0.6154484735\t\ttotal: 20.1s\tremaining: 12m 38s\n",
      "31:\tlearn 0.6253519876\ttest 0.6169674066\tbestTest 0.6169674066\t\ttotal: 20.7s\tremaining: 12m 34s\n",
      "32:\tlearn 0.6255785613\ttest 0.61773967\tbestTest 0.61773967\t\ttotal: 21.3s\tremaining: 12m 33s\n",
      "33:\tlearn 0.6260003119\ttest 0.6176999654\tbestTest 0.61773967\t\ttotal: 22s\tremaining: 12m 33s\n",
      "34:\tlearn 0.6274015956\ttest 0.6189787421\tbestTest 0.6189787421\t\ttotal: 22.7s\tremaining: 12m 34s\n",
      "35:\tlearn 0.6276196017\ttest 0.6190459693\tbestTest 0.6190459693\t\ttotal: 23.4s\tremaining: 12m 36s\n",
      "36:\tlearn 0.6277539161\ttest 0.6190410446\tbestTest 0.6190459693\t\ttotal: 24.1s\tremaining: 12m 36s\n",
      "37:\tlearn 0.6272950144\ttest 0.6188431104\tbestTest 0.6190459693\t\ttotal: 24.7s\tremaining: 12m 35s\n",
      "38:\tlearn 0.6278843249\ttest 0.6195071802\tbestTest 0.6195071802\t\ttotal: 25.3s\tremaining: 12m 34s\n",
      "39:\tlearn 0.6289395564\ttest 0.6202905567\tbestTest 0.6202905567\t\ttotal: 26s\tremaining: 12m 34s\n",
      "40:\tlearn 0.6296851257\ttest 0.6205504178\tbestTest 0.6205504178\t\ttotal: 26.7s\tremaining: 12m 34s\n",
      "41:\tlearn 0.6308238213\ttest 0.6213890021\tbestTest 0.6213890021\t\ttotal: 27.3s\tremaining: 12m 33s\n",
      "42:\tlearn 0.6307690764\ttest 0.6217583145\tbestTest 0.6217583145\t\ttotal: 28s\tremaining: 12m 33s\n",
      "43:\tlearn 0.6315129248\ttest 0.6223381168\tbestTest 0.6223381168\t\ttotal: 28.7s\tremaining: 12m 34s\n",
      "44:\tlearn 0.632164075\ttest 0.6229447224\tbestTest 0.6229447224\t\ttotal: 29.4s\tremaining: 12m 34s\n",
      "45:\tlearn 0.6321493057\ttest 0.6229317889\tbestTest 0.6229447224\t\ttotal: 30.1s\tremaining: 12m 33s\n",
      "46:\tlearn 0.6319710739\ttest 0.62296681\tbestTest 0.62296681\t\ttotal: 30.7s\tremaining: 12m 33s\n",
      "47:\tlearn 0.6321302835\ttest 0.6234844384\tbestTest 0.6234844384\t\ttotal: 31.3s\tremaining: 12m 31s\n",
      "48:\tlearn 0.6319451879\ttest 0.6234593591\tbestTest 0.6234844384\t\ttotal: 32s\tremaining: 12m 32s\n",
      "49:\tlearn 0.6321112806\ttest 0.6232960782\tbestTest 0.6234844384\t\ttotal: 32.7s\tremaining: 12m 31s\n",
      "50:\tlearn 0.6322913262\ttest 0.6232863675\tbestTest 0.6234844384\t\ttotal: 33.3s\tremaining: 12m 31s\n",
      "51:\tlearn 0.63259946\ttest 0.6237135721\tbestTest 0.6237135721\t\ttotal: 34s\tremaining: 12m 29s\n",
      "52:\tlearn 0.6328309793\ttest 0.6238099775\tbestTest 0.6238099775\t\ttotal: 34.7s\tremaining: 12m 30s\n",
      "53:\tlearn 0.6326761911\ttest 0.6236571245\tbestTest 0.6238099775\t\ttotal: 35.4s\tremaining: 12m 30s\n",
      "54:\tlearn 0.6327939002\ttest 0.6236101385\tbestTest 0.6238099775\t\ttotal: 36s\tremaining: 12m 30s\n",
      "55:\tlearn 0.633152052\ttest 0.6241121732\tbestTest 0.6241121732\t\ttotal: 36.7s\tremaining: 12m 29s\n",
      "56:\tlearn 0.6335010662\ttest 0.6244527032\tbestTest 0.6244527032\t\ttotal: 37.4s\tremaining: 12m 29s\n",
      "57:\tlearn 0.6340242635\ttest 0.6250534619\tbestTest 0.6250534619\t\ttotal: 38s\tremaining: 12m 29s\n",
      "58:\tlearn 0.6342495482\ttest 0.6251264796\tbestTest 0.6251264796\t\ttotal: 38.7s\tremaining: 12m 29s\n",
      "59:\tlearn 0.6342094\ttest 0.6252648962\tbestTest 0.6252648962\t\ttotal: 39.4s\tremaining: 12m 29s\n",
      "60:\tlearn 0.6342503323\ttest 0.6251861963\tbestTest 0.6252648962\t\ttotal: 40.1s\tremaining: 12m 29s\n",
      "61:\tlearn 0.6340893893\ttest 0.6251936666\tbestTest 0.6252648962\t\ttotal: 40.8s\tremaining: 12m 29s\n",
      "62:\tlearn 0.6344041987\ttest 0.6255112049\tbestTest 0.6255112049\t\ttotal: 41.5s\tremaining: 12m 29s\n",
      "63:\tlearn 0.6348824969\ttest 0.6257393018\tbestTest 0.6257393018\t\ttotal: 42.2s\tremaining: 12m 29s\n",
      "64:\tlearn 0.63478548\ttest 0.6255031157\tbestTest 0.6257393018\t\ttotal: 42.9s\tremaining: 12m 29s\n",
      "65:\tlearn 0.6351432663\ttest 0.6260334204\tbestTest 0.6260334204\t\ttotal: 43.6s\tremaining: 12m 29s\n",
      "66:\tlearn 0.6354294887\ttest 0.6262963334\tbestTest 0.6262963334\t\ttotal: 44.3s\tremaining: 12m 28s\n",
      "67:\tlearn 0.6352812369\ttest 0.626147276\tbestTest 0.6262963334\t\ttotal: 44.9s\tremaining: 12m 28s\n",
      "68:\tlearn 0.6352761078\ttest 0.6261876295\tbestTest 0.6262963334\t\ttotal: 45.6s\tremaining: 12m 27s\n",
      "69:\tlearn 0.6351919307\ttest 0.6261654154\tbestTest 0.6262963334\t\ttotal: 46.3s\tremaining: 12m 27s\n",
      "70:\tlearn 0.6352782177\ttest 0.6262069303\tbestTest 0.6262963334\t\ttotal: 47s\tremaining: 12m 27s\n",
      "71:\tlearn 0.6353085565\ttest 0.6265045068\tbestTest 0.6265045068\t\ttotal: 47.6s\tremaining: 12m 26s\n",
      "72:\tlearn 0.6353485381\ttest 0.6265857303\tbestTest 0.6265857303\t\ttotal: 48.3s\tremaining: 12m 26s\n",
      "73:\tlearn 0.6354618269\ttest 0.626625244\tbestTest 0.626625244\t\ttotal: 49s\tremaining: 12m 25s\n",
      "74:\tlearn 0.6356550842\ttest 0.6269580665\tbestTest 0.6269580665\t\ttotal: 49.7s\tremaining: 12m 25s\n",
      "75:\tlearn 0.6361120973\ttest 0.627605952\tbestTest 0.627605952\t\ttotal: 50.4s\tremaining: 12m 25s\n",
      "76:\tlearn 0.6362250502\ttest 0.6276977461\tbestTest 0.6276977461\t\ttotal: 51s\tremaining: 12m 24s\n",
      "77:\tlearn 0.6363655815\ttest 0.6278314449\tbestTest 0.6278314449\t\ttotal: 51.7s\tremaining: 12m 23s\n",
      "78:\tlearn 0.6365413191\ttest 0.6281042475\tbestTest 0.6281042475\t\ttotal: 52.4s\tremaining: 12m 23s\n",
      "79:\tlearn 0.636713011\ttest 0.628237454\tbestTest 0.628237454\t\ttotal: 53.1s\tremaining: 12m 22s\n",
      "80:\tlearn 0.6367034093\ttest 0.6283162725\tbestTest 0.6283162725\t\ttotal: 53.8s\tremaining: 12m 22s\n",
      "81:\tlearn 0.636793594\ttest 0.628450558\tbestTest 0.628450558\t\ttotal: 54.4s\tremaining: 12m 22s\n",
      "82:\tlearn 0.6367596192\ttest 0.6285414902\tbestTest 0.6285414902\t\ttotal: 55.1s\tremaining: 12m 22s\n",
      "83:\tlearn 0.6367359827\ttest 0.6285188702\tbestTest 0.6285414902\t\ttotal: 55.8s\tremaining: 12m 21s\n",
      "84:\tlearn 0.6367516308\ttest 0.6285572426\tbestTest 0.6285572426\t\ttotal: 56.5s\tremaining: 12m 21s\n",
      "85:\tlearn 0.6366739776\ttest 0.6285313214\tbestTest 0.6285572426\t\ttotal: 57.2s\tremaining: 12m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86:\tlearn 0.6366608634\ttest 0.6285884542\tbestTest 0.6285884542\t\ttotal: 57.9s\tremaining: 12m 20s\n",
      "87:\tlearn 0.6367442068\ttest 0.6287441904\tbestTest 0.6287441904\t\ttotal: 58.6s\tremaining: 12m 20s\n",
      "88:\tlearn 0.6369154836\ttest 0.6288335774\tbestTest 0.6288335774\t\ttotal: 59.3s\tremaining: 12m 20s\n",
      "89:\tlearn 0.6370903664\ttest 0.6290878588\tbestTest 0.6290878588\t\ttotal: 1m\tremaining: 12m 20s\n",
      "90:\tlearn 0.6371688537\ttest 0.629277955\tbestTest 0.629277955\t\ttotal: 1m\tremaining: 12m 19s\n",
      "91:\tlearn 0.6372514619\ttest 0.6291631731\tbestTest 0.629277955\t\ttotal: 1m 1s\tremaining: 12m 18s\n",
      "92:\tlearn 0.6371566616\ttest 0.629167487\tbestTest 0.629277955\t\ttotal: 1m 1s\tremaining: 12m 17s\n",
      "93:\tlearn 0.6371944492\ttest 0.6293040229\tbestTest 0.6293040229\t\ttotal: 1m 2s\tremaining: 12m 16s\n",
      "94:\tlearn 0.6371603828\ttest 0.6293693874\tbestTest 0.6293693874\t\ttotal: 1m 3s\tremaining: 12m 15s\n",
      "95:\tlearn 0.6370973484\ttest 0.6293801369\tbestTest 0.6293801369\t\ttotal: 1m 3s\tremaining: 12m 14s\n",
      "96:\tlearn 0.6371627008\ttest 0.6294244828\tbestTest 0.6294244828\t\ttotal: 1m 4s\tremaining: 12m 14s\n",
      "97:\tlearn 0.6372837932\ttest 0.6295123609\tbestTest 0.6295123609\t\ttotal: 1m 5s\tremaining: 12m 14s\n",
      "98:\tlearn 0.6373183373\ttest 0.6295996504\tbestTest 0.6295996504\t\ttotal: 1m 5s\tremaining: 12m 12s\n",
      "99:\tlearn 0.637294636\ttest 0.6295497067\tbestTest 0.6295996504\t\ttotal: 1m 6s\tremaining: 12m 12s\n",
      "100:\tlearn 0.6373664639\ttest 0.6295592124\tbestTest 0.6295996504\t\ttotal: 1m 7s\tremaining: 12m 11s\n",
      "101:\tlearn 0.63770485\ttest 0.6298908615\tbestTest 0.6298908615\t\ttotal: 1m 7s\tremaining: 12m 11s\n",
      "102:\tlearn 0.6379496116\ttest 0.6299788803\tbestTest 0.6299788803\t\ttotal: 1m 8s\tremaining: 12m 10s\n",
      "103:\tlearn 0.6380354493\ttest 0.6300934371\tbestTest 0.6300934371\t\ttotal: 1m 9s\tremaining: 12m 10s\n",
      "104:\tlearn 0.6380523821\ttest 0.6301293382\tbestTest 0.6301293382\t\ttotal: 1m 9s\tremaining: 12m 9s\n",
      "105:\tlearn 0.6381520204\ttest 0.630180381\tbestTest 0.630180381\t\ttotal: 1m 10s\tremaining: 12m 9s\n",
      "106:\tlearn 0.6381961679\ttest 0.6301954121\tbestTest 0.6301954121\t\ttotal: 1m 11s\tremaining: 12m 9s\n",
      "107:\tlearn 0.6383067842\ttest 0.6303482409\tbestTest 0.6303482409\t\ttotal: 1m 12s\tremaining: 12m 8s\n",
      "108:\tlearn 0.6385259581\ttest 0.6305300369\tbestTest 0.6305300369\t\ttotal: 1m 12s\tremaining: 12m 8s\n",
      "109:\tlearn 0.6385758211\ttest 0.6305422712\tbestTest 0.6305422712\t\ttotal: 1m 13s\tremaining: 12m 7s\n",
      "110:\tlearn 0.6386100051\ttest 0.6306379512\tbestTest 0.6306379512\t\ttotal: 1m 14s\tremaining: 12m 6s\n",
      "111:\tlearn 0.6387043051\ttest 0.6307348849\tbestTest 0.6307348849\t\ttotal: 1m 14s\tremaining: 12m 6s\n",
      "112:\tlearn 0.6388255062\ttest 0.6307235569\tbestTest 0.6307348849\t\ttotal: 1m 15s\tremaining: 12m 5s\n",
      "113:\tlearn 0.6390020224\ttest 0.6307488351\tbestTest 0.6307488351\t\ttotal: 1m 16s\tremaining: 12m 4s\n",
      "114:\tlearn 0.6392103911\ttest 0.6310115191\tbestTest 0.6310115191\t\ttotal: 1m 16s\tremaining: 12m 4s\n",
      "115:\tlearn 0.6393251937\ttest 0.6310772775\tbestTest 0.6310772775\t\ttotal: 1m 17s\tremaining: 12m 3s\n",
      "116:\tlearn 0.6394267441\ttest 0.6312799013\tbestTest 0.6312799013\t\ttotal: 1m 18s\tremaining: 12m 2s\n",
      "117:\tlearn 0.6394579381\ttest 0.6312707794\tbestTest 0.6312799013\t\ttotal: 1m 18s\tremaining: 12m 1s\n",
      "118:\tlearn 0.639633691\ttest 0.6314746489\tbestTest 0.6314746489\t\ttotal: 1m 19s\tremaining: 12m 1s\n",
      "119:\tlearn 0.6396299312\ttest 0.6314924528\tbestTest 0.6314924528\t\ttotal: 1m 20s\tremaining: 12m\n",
      "120:\tlearn 0.6397090431\ttest 0.6314875804\tbestTest 0.6314924528\t\ttotal: 1m 20s\tremaining: 11m 59s\n",
      "121:\tlearn 0.6398079607\ttest 0.6315304957\tbestTest 0.6315304957\t\ttotal: 1m 21s\tremaining: 11m 59s\n",
      "122:\tlearn 0.6398589429\ttest 0.6315706745\tbestTest 0.6315706745\t\ttotal: 1m 22s\tremaining: 11m 59s\n",
      "123:\tlearn 0.639969181\ttest 0.6317401981\tbestTest 0.6317401981\t\ttotal: 1m 22s\tremaining: 11m 59s\n",
      "124:\tlearn 0.6400574442\ttest 0.6317852573\tbestTest 0.6317852573\t\ttotal: 1m 23s\tremaining: 11m 58s\n",
      "125:\tlearn 0.6400715039\ttest 0.6317940598\tbestTest 0.6317940598\t\ttotal: 1m 24s\tremaining: 11m 57s\n",
      "126:\tlearn 0.6402574473\ttest 0.63193241\tbestTest 0.63193241\t\ttotal: 1m 24s\tremaining: 11m 57s\n",
      "127:\tlearn 0.6402577538\ttest 0.6319582448\tbestTest 0.6319582448\t\ttotal: 1m 25s\tremaining: 11m 56s\n",
      "128:\tlearn 0.640514663\ttest 0.6321077945\tbestTest 0.6321077945\t\ttotal: 1m 26s\tremaining: 11m 56s\n",
      "129:\tlearn 0.6408036218\ttest 0.6323931588\tbestTest 0.6323931588\t\ttotal: 1m 26s\tremaining: 11m 55s\n",
      "130:\tlearn 0.6409213683\ttest 0.6325934821\tbestTest 0.6325934821\t\ttotal: 1m 27s\tremaining: 11m 54s\n",
      "131:\tlearn 0.6409044208\ttest 0.6326174242\tbestTest 0.6326174242\t\ttotal: 1m 28s\tremaining: 11m 53s\n",
      "132:\tlearn 0.6409024382\ttest 0.6325539643\tbestTest 0.6326174242\t\ttotal: 1m 28s\tremaining: 11m 53s\n",
      "133:\tlearn 0.640985644\ttest 0.6325609243\tbestTest 0.6326174242\t\ttotal: 1m 29s\tremaining: 11m 52s\n",
      "134:\tlearn 0.6411575242\ttest 0.6325511494\tbestTest 0.6326174242\t\ttotal: 1m 30s\tremaining: 11m 51s\n",
      "135:\tlearn 0.6412620922\ttest 0.6326875366\tbestTest 0.6326875366\t\ttotal: 1m 30s\tremaining: 11m 51s\n",
      "136:\tlearn 0.6412953509\ttest 0.6327050089\tbestTest 0.6327050089\t\ttotal: 1m 31s\tremaining: 11m 50s\n",
      "137:\tlearn 0.6413351521\ttest 0.632629994\tbestTest 0.6327050089\t\ttotal: 1m 32s\tremaining: 11m 50s\n",
      "138:\tlearn 0.6415101252\ttest 0.6326216998\tbestTest 0.6327050089\t\ttotal: 1m 32s\tremaining: 11m 49s\n",
      "139:\tlearn 0.6417328724\ttest 0.632837016\tbestTest 0.632837016\t\ttotal: 1m 33s\tremaining: 11m 49s\n",
      "140:\tlearn 0.6418789171\ttest 0.6328957541\tbestTest 0.6328957541\t\ttotal: 1m 34s\tremaining: 11m 48s\n",
      "141:\tlearn 0.6420784719\ttest 0.6330036985\tbestTest 0.6330036985\t\ttotal: 1m 34s\tremaining: 11m 47s\n",
      "142:\tlearn 0.6421061225\ttest 0.6330106465\tbestTest 0.6330106465\t\ttotal: 1m 35s\tremaining: 11m 47s\n",
      "143:\tlearn 0.6420709802\ttest 0.632975101\tbestTest 0.6330106465\t\ttotal: 1m 36s\tremaining: 11m 45s\n",
      "144:\tlearn 0.642032657\ttest 0.6328940282\tbestTest 0.6330106465\t\ttotal: 1m 36s\tremaining: 11m 44s\n",
      "145:\tlearn 0.6420609839\ttest 0.6328833792\tbestTest 0.6330106465\t\ttotal: 1m 37s\tremaining: 11m 43s\n",
      "146:\tlearn 0.6421801791\ttest 0.6329936081\tbestTest 0.6330106465\t\ttotal: 1m 38s\tremaining: 11m 43s\n",
      "147:\tlearn 0.6422738852\ttest 0.6329818983\tbestTest 0.6330106465\t\ttotal: 1m 38s\tremaining: 11m 42s\n",
      "148:\tlearn 0.6423821078\ttest 0.6330253903\tbestTest 0.6330253903\t\ttotal: 1m 39s\tremaining: 11m 41s\n",
      "149:\tlearn 0.642421959\ttest 0.6330553802\tbestTest 0.6330553802\t\ttotal: 1m 40s\tremaining: 11m 40s\n",
      "150:\tlearn 0.6425696983\ttest 0.6331855267\tbestTest 0.6331855267\t\ttotal: 1m 40s\tremaining: 11m 40s\n",
      "151:\tlearn 0.6427456605\ttest 0.6332748977\tbestTest 0.6332748977\t\ttotal: 1m 41s\tremaining: 11m 39s\n",
      "152:\tlearn 0.6428708808\ttest 0.6332671641\tbestTest 0.6332748977\t\ttotal: 1m 42s\tremaining: 11m 38s\n",
      "153:\tlearn 0.6430173292\ttest 0.6333024504\tbestTest 0.6333024504\t\ttotal: 1m 42s\tremaining: 11m 38s\n",
      "154:\tlearn 0.6431061025\ttest 0.6333216004\tbestTest 0.6333216004\t\ttotal: 1m 43s\tremaining: 11m 38s\n",
      "155:\tlearn 0.643262022\ttest 0.6334026974\tbestTest 0.6334026974\t\ttotal: 1m 44s\tremaining: 11m 37s\n",
      "156:\tlearn 0.6433922414\ttest 0.6334717108\tbestTest 0.6334717108\t\ttotal: 1m 44s\tremaining: 11m 37s\n",
      "157:\tlearn 0.6435073591\ttest 0.6334722191\tbestTest 0.6334722191\t\ttotal: 1m 45s\tremaining: 11m 36s\n",
      "158:\tlearn 0.6435994099\ttest 0.6334720563\tbestTest 0.6334722191\t\ttotal: 1m 46s\tremaining: 11m 36s\n",
      "159:\tlearn 0.6437801655\ttest 0.6335186627\tbestTest 0.6335186627\t\ttotal: 1m 47s\tremaining: 11m 35s\n",
      "160:\tlearn 0.6439407377\ttest 0.6335387008\tbestTest 0.6335387008\t\ttotal: 1m 47s\tremaining: 11m 35s\n",
      "161:\tlearn 0.6441308632\ttest 0.6336574951\tbestTest 0.6336574951\t\ttotal: 1m 48s\tremaining: 11m 35s\n",
      "162:\tlearn 0.6444110506\ttest 0.6338364883\tbestTest 0.6338364883\t\ttotal: 1m 49s\tremaining: 11m 34s\n",
      "163:\tlearn 0.6444752174\ttest 0.6339114429\tbestTest 0.6339114429\t\ttotal: 1m 49s\tremaining: 11m 33s\n",
      "164:\tlearn 0.6445464182\ttest 0.6340192186\tbestTest 0.6340192186\t\ttotal: 1m 50s\tremaining: 11m 33s\n",
      "165:\tlearn 0.6446471141\ttest 0.6340653688\tbestTest 0.6340653688\t\ttotal: 1m 51s\tremaining: 11m 32s\n",
      "166:\tlearn 0.6447359206\ttest 0.6341076251\tbestTest 0.6341076251\t\ttotal: 1m 51s\tremaining: 11m 31s\n",
      "167:\tlearn 0.6449978269\ttest 0.6341842515\tbestTest 0.6341842515\t\ttotal: 1m 52s\tremaining: 11m 31s\n",
      "168:\tlearn 0.6451238492\ttest 0.6342446412\tbestTest 0.6342446412\t\ttotal: 1m 53s\tremaining: 11m 31s\n",
      "169:\tlearn 0.6453731521\ttest 0.6343638293\tbestTest 0.6343638293\t\ttotal: 1m 54s\tremaining: 11m 30s\n",
      "170:\tlearn 0.6454339837\ttest 0.6343655512\tbestTest 0.6343655512\t\ttotal: 1m 54s\tremaining: 11m 30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171:\tlearn 0.6455650839\ttest 0.6343701183\tbestTest 0.6343701183\t\ttotal: 1m 55s\tremaining: 11m 29s\n",
      "172:\tlearn 0.6456143334\ttest 0.6344028849\tbestTest 0.6344028849\t\ttotal: 1m 56s\tremaining: 11m 29s\n",
      "173:\tlearn 0.6456838104\ttest 0.6344519646\tbestTest 0.6344519646\t\ttotal: 1m 56s\tremaining: 11m 28s\n",
      "174:\tlearn 0.6458081238\ttest 0.6345712874\tbestTest 0.6345712874\t\ttotal: 1m 57s\tremaining: 11m 28s\n",
      "175:\tlearn 0.6459204694\ttest 0.6345549141\tbestTest 0.6345712874\t\ttotal: 1m 58s\tremaining: 11m 27s\n",
      "176:\tlearn 0.64595147\ttest 0.6345679078\tbestTest 0.6345712874\t\ttotal: 1m 58s\tremaining: 11m 26s\n",
      "177:\tlearn 0.6460553528\ttest 0.634645788\tbestTest 0.634645788\t\ttotal: 1m 59s\tremaining: 11m 26s\n",
      "178:\tlearn 0.6462119467\ttest 0.634738874\tbestTest 0.634738874\t\ttotal: 2m\tremaining: 11m 25s\n",
      "179:\tlearn 0.646401705\ttest 0.6347642206\tbestTest 0.6347642206\t\ttotal: 2m\tremaining: 11m 24s\n",
      "180:\tlearn 0.6465034262\ttest 0.6347760229\tbestTest 0.6347760229\t\ttotal: 2m 1s\tremaining: 11m 23s\n",
      "181:\tlearn 0.6466631453\ttest 0.6347940337\tbestTest 0.6347940337\t\ttotal: 2m 2s\tremaining: 11m 23s\n",
      "182:\tlearn 0.6467708147\ttest 0.6348981023\tbestTest 0.6348981023\t\ttotal: 2m 2s\tremaining: 11m 22s\n",
      "183:\tlearn 0.6468588772\ttest 0.6350067278\tbestTest 0.6350067278\t\ttotal: 2m 3s\tremaining: 11m 22s\n",
      "184:\tlearn 0.6469492161\ttest 0.6349476702\tbestTest 0.6350067278\t\ttotal: 2m 4s\tremaining: 11m 21s\n",
      "185:\tlearn 0.6470801516\ttest 0.6350272462\tbestTest 0.6350272462\t\ttotal: 2m 4s\tremaining: 11m 20s\n",
      "186:\tlearn 0.6471641871\ttest 0.6350783612\tbestTest 0.6350783612\t\ttotal: 2m 5s\tremaining: 11m 19s\n",
      "187:\tlearn 0.647376773\ttest 0.6351003966\tbestTest 0.6351003966\t\ttotal: 2m 6s\tremaining: 11m 18s\n",
      "188:\tlearn 0.6474467658\ttest 0.6350876198\tbestTest 0.6351003966\t\ttotal: 2m 6s\tremaining: 11m 18s\n",
      "189:\tlearn 0.6474929926\ttest 0.6351470612\tbestTest 0.6351470612\t\ttotal: 2m 7s\tremaining: 11m 19s\n",
      "190:\tlearn 0.647670275\ttest 0.635206603\tbestTest 0.635206603\t\ttotal: 2m 8s\tremaining: 11m 19s\n",
      "191:\tlearn 0.6476975081\ttest 0.6351902076\tbestTest 0.635206603\t\ttotal: 2m 9s\tremaining: 11m 20s\n",
      "192:\tlearn 0.6478882044\ttest 0.6352392772\tbestTest 0.6352392772\t\ttotal: 2m 10s\tremaining: 11m 21s\n",
      "193:\tlearn 0.6479267479\ttest 0.6352537759\tbestTest 0.6352537759\t\ttotal: 2m 11s\tremaining: 11m 21s\n",
      "194:\tlearn 0.6480519273\ttest 0.635328807\tbestTest 0.635328807\t\ttotal: 2m 12s\tremaining: 11m 21s\n",
      "195:\tlearn 0.6481256876\ttest 0.6353134061\tbestTest 0.635328807\t\ttotal: 2m 13s\tremaining: 11m 21s\n",
      "196:\tlearn 0.6481999601\ttest 0.6353003742\tbestTest 0.635328807\t\ttotal: 2m 13s\tremaining: 11m 22s\n",
      "197:\tlearn 0.6483142564\ttest 0.6353097875\tbestTest 0.635328807\t\ttotal: 2m 14s\tremaining: 11m 22s\n",
      "198:\tlearn 0.6484531381\ttest 0.6353738822\tbestTest 0.6353738822\t\ttotal: 2m 15s\tremaining: 11m 22s\n",
      "199:\tlearn 0.6486161161\ttest 0.6353467897\tbestTest 0.6353738822\t\ttotal: 2m 16s\tremaining: 11m 22s\n",
      "200:\tlearn 0.6487122591\ttest 0.6353032253\tbestTest 0.6353738822\t\ttotal: 2m 17s\tremaining: 11m 22s\n",
      "201:\tlearn 0.6486924953\ttest 0.6352917867\tbestTest 0.6353738822\t\ttotal: 2m 18s\tremaining: 11m 22s\n",
      "202:\tlearn 0.6486796167\ttest 0.6352962251\tbestTest 0.6353738822\t\ttotal: 2m 18s\tremaining: 11m 21s\n",
      "203:\tlearn 0.6488154899\ttest 0.6354292428\tbestTest 0.6354292428\t\ttotal: 2m 19s\tremaining: 11m 21s\n",
      "204:\tlearn 0.6488870489\ttest 0.6354661184\tbestTest 0.6354661184\t\ttotal: 2m 20s\tremaining: 11m 21s\n",
      "205:\tlearn 0.6489831852\ttest 0.6354294176\tbestTest 0.6354661184\t\ttotal: 2m 21s\tremaining: 11m 21s\n",
      "206:\tlearn 0.6491001939\ttest 0.6355128614\tbestTest 0.6355128614\t\ttotal: 2m 22s\tremaining: 11m 22s\n",
      "207:\tlearn 0.649090852\ttest 0.6355075148\tbestTest 0.6355128614\t\ttotal: 2m 22s\tremaining: 11m 20s\n",
      "208:\tlearn 0.6491722977\ttest 0.6355458109\tbestTest 0.6355458109\t\ttotal: 2m 23s\tremaining: 11m 20s\n",
      "209:\tlearn 0.6492642453\ttest 0.6355613785\tbestTest 0.6355613785\t\ttotal: 2m 24s\tremaining: 11m 20s\n",
      "210:\tlearn 0.6494183402\ttest 0.6356301909\tbestTest 0.6356301909\t\ttotal: 2m 25s\tremaining: 11m 20s\n",
      "211:\tlearn 0.6495230381\ttest 0.6356218184\tbestTest 0.6356301909\t\ttotal: 2m 26s\tremaining: 11m 20s\n",
      "212:\tlearn 0.6495633546\ttest 0.6356563492\tbestTest 0.6356563492\t\ttotal: 2m 26s\tremaining: 11m 20s\n",
      "213:\tlearn 0.6496963504\ttest 0.6357124512\tbestTest 0.6357124512\t\ttotal: 2m 27s\tremaining: 11m 20s\n",
      "214:\tlearn 0.6498736708\ttest 0.6357109644\tbestTest 0.6357124512\t\ttotal: 2m 28s\tremaining: 11m 20s\n",
      "215:\tlearn 0.6499472947\ttest 0.6356987924\tbestTest 0.6357124512\t\ttotal: 2m 29s\tremaining: 11m 20s\n",
      "216:\tlearn 0.6501089963\ttest 0.6356952561\tbestTest 0.6357124512\t\ttotal: 2m 30s\tremaining: 11m 20s\n",
      "217:\tlearn 0.6501456142\ttest 0.6357043821\tbestTest 0.6357124512\t\ttotal: 2m 31s\tremaining: 11m 20s\n",
      "218:\tlearn 0.650255232\ttest 0.6357242093\tbestTest 0.6357242093\t\ttotal: 2m 32s\tremaining: 11m 20s\n",
      "219:\tlearn 0.6504143112\ttest 0.6357658689\tbestTest 0.6357658689\t\ttotal: 2m 32s\tremaining: 11m 20s\n",
      "220:\tlearn 0.6504574851\ttest 0.6357388828\tbestTest 0.6357658689\t\ttotal: 2m 33s\tremaining: 11m 20s\n",
      "221:\tlearn 0.6505694783\ttest 0.6357445649\tbestTest 0.6357658689\t\ttotal: 2m 34s\tremaining: 11m 20s\n",
      "222:\tlearn 0.6506676487\ttest 0.635762636\tbestTest 0.6357658689\t\ttotal: 2m 35s\tremaining: 11m 20s\n",
      "223:\tlearn 0.6507544197\ttest 0.6357828208\tbestTest 0.6357828208\t\ttotal: 2m 36s\tremaining: 11m 20s\n",
      "224:\tlearn 0.6508587537\ttest 0.635799158\tbestTest 0.635799158\t\ttotal: 2m 37s\tremaining: 11m 20s\n",
      "225:\tlearn 0.6510337682\ttest 0.6359003433\tbestTest 0.6359003433\t\ttotal: 2m 37s\tremaining: 11m 20s\n",
      "226:\tlearn 0.6511406462\ttest 0.6359570782\tbestTest 0.6359570782\t\ttotal: 2m 38s\tremaining: 11m 20s\n",
      "227:\tlearn 0.6514015748\ttest 0.6359691175\tbestTest 0.6359691175\t\ttotal: 2m 39s\tremaining: 11m 20s\n",
      "228:\tlearn 0.651490362\ttest 0.6359781772\tbestTest 0.6359781772\t\ttotal: 2m 40s\tremaining: 11m 20s\n",
      "229:\tlearn 0.65161008\ttest 0.6360107811\tbestTest 0.6360107811\t\ttotal: 2m 41s\tremaining: 11m 19s\n",
      "230:\tlearn 0.6516878695\ttest 0.6359459791\tbestTest 0.6360107811\t\ttotal: 2m 42s\tremaining: 11m 19s\n",
      "231:\tlearn 0.6518966727\ttest 0.6359910685\tbestTest 0.6360107811\t\ttotal: 2m 42s\tremaining: 11m 19s\n",
      "232:\tlearn 0.6520166312\ttest 0.6360256375\tbestTest 0.6360256375\t\ttotal: 2m 43s\tremaining: 11m 19s\n",
      "233:\tlearn 0.6521215704\ttest 0.6360297745\tbestTest 0.6360297745\t\ttotal: 2m 44s\tremaining: 11m 19s\n",
      "234:\tlearn 0.652326463\ttest 0.6360421072\tbestTest 0.6360421072\t\ttotal: 2m 45s\tremaining: 11m 18s\n",
      "235:\tlearn 0.6524408367\ttest 0.6360376809\tbestTest 0.6360421072\t\ttotal: 2m 46s\tremaining: 11m 18s\n",
      "236:\tlearn 0.6525573038\ttest 0.6361047593\tbestTest 0.6361047593\t\ttotal: 2m 46s\tremaining: 11m 17s\n",
      "237:\tlearn 0.6526184181\ttest 0.6361167706\tbestTest 0.6361167706\t\ttotal: 2m 47s\tremaining: 11m 16s\n",
      "238:\tlearn 0.6528297402\ttest 0.6361221413\tbestTest 0.6361221413\t\ttotal: 2m 48s\tremaining: 11m 15s\n",
      "239:\tlearn 0.652885436\ttest 0.6361280203\tbestTest 0.6361280203\t\ttotal: 2m 48s\tremaining: 11m 15s\n",
      "240:\tlearn 0.6530177017\ttest 0.6361326054\tbestTest 0.6361326054\t\ttotal: 2m 49s\tremaining: 11m 14s\n",
      "241:\tlearn 0.6531741493\ttest 0.6361293625\tbestTest 0.6361326054\t\ttotal: 2m 50s\tremaining: 11m 13s\n",
      "242:\tlearn 0.6532445996\ttest 0.6361574295\tbestTest 0.6361574295\t\ttotal: 2m 50s\tremaining: 11m 12s\n",
      "243:\tlearn 0.6533942139\ttest 0.6362380382\tbestTest 0.6362380382\t\ttotal: 2m 51s\tremaining: 11m 11s\n",
      "244:\tlearn 0.6534489093\ttest 0.6363291834\tbestTest 0.6363291834\t\ttotal: 2m 52s\tremaining: 11m 10s\n",
      "245:\tlearn 0.653504038\ttest 0.6363154603\tbestTest 0.6363291834\t\ttotal: 2m 52s\tremaining: 11m 9s\n",
      "246:\tlearn 0.6535745494\ttest 0.6363859966\tbestTest 0.6363859966\t\ttotal: 2m 53s\tremaining: 11m 9s\n",
      "247:\tlearn 0.6537220033\ttest 0.6364444354\tbestTest 0.6364444354\t\ttotal: 2m 54s\tremaining: 11m 8s\n",
      "248:\tlearn 0.6538923304\ttest 0.6364187091\tbestTest 0.6364444354\t\ttotal: 2m 54s\tremaining: 11m 7s\n",
      "249:\tlearn 0.6539857695\ttest 0.6364899929\tbestTest 0.6364899929\t\ttotal: 2m 55s\tremaining: 11m 6s\n",
      "250:\tlearn 0.6540506305\ttest 0.6364955404\tbestTest 0.6364955404\t\ttotal: 2m 56s\tremaining: 11m 6s\n",
      "251:\tlearn 0.6540453887\ttest 0.6365064687\tbestTest 0.6365064687\t\ttotal: 2m 56s\tremaining: 11m 4s\n",
      "252:\tlearn 0.6541827359\ttest 0.6365384337\tbestTest 0.6365384337\t\ttotal: 2m 57s\tremaining: 11m 3s\n",
      "253:\tlearn 0.6542194797\ttest 0.636527638\tbestTest 0.6365384337\t\ttotal: 2m 58s\tremaining: 11m 3s\n",
      "254:\tlearn 0.6542098798\ttest 0.6365272542\tbestTest 0.6365384337\t\ttotal: 2m 58s\tremaining: 11m 2s\n",
      "255:\tlearn 0.6543077941\ttest 0.6365002059\tbestTest 0.6365384337\t\ttotal: 2m 59s\tremaining: 11m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256:\tlearn 0.6545638302\ttest 0.6366717045\tbestTest 0.6366717045\t\ttotal: 3m\tremaining: 11m\n",
      "257:\tlearn 0.6547229876\ttest 0.6366703242\tbestTest 0.6366717045\t\ttotal: 3m\tremaining: 10m 59s\n",
      "258:\tlearn 0.6547917753\ttest 0.6366590403\tbestTest 0.6366717045\t\ttotal: 3m 1s\tremaining: 10m 59s\n",
      "259:\tlearn 0.6549925764\ttest 0.6367013147\tbestTest 0.6367013147\t\ttotal: 3m 2s\tremaining: 10m 58s\n",
      "260:\tlearn 0.6550437625\ttest 0.6367237177\tbestTest 0.6367237177\t\ttotal: 3m 2s\tremaining: 10m 57s\n",
      "261:\tlearn 0.6550896881\ttest 0.6367352387\tbestTest 0.6367352387\t\ttotal: 3m 3s\tremaining: 10m 56s\n",
      "262:\tlearn 0.6552467038\ttest 0.6367678868\tbestTest 0.6367678868\t\ttotal: 3m 4s\tremaining: 10m 55s\n",
      "263:\tlearn 0.6553554784\ttest 0.6368049372\tbestTest 0.6368049372\t\ttotal: 3m 4s\tremaining: 10m 54s\n",
      "264:\tlearn 0.6553794551\ttest 0.6368030345\tbestTest 0.6368049372\t\ttotal: 3m 5s\tremaining: 10m 54s\n",
      "265:\tlearn 0.655519623\ttest 0.636808369\tbestTest 0.636808369\t\ttotal: 3m 6s\tremaining: 10m 53s\n",
      "266:\tlearn 0.6556512119\ttest 0.6368286221\tbestTest 0.6368286221\t\ttotal: 3m 6s\tremaining: 10m 52s\n",
      "267:\tlearn 0.655720958\ttest 0.6368887647\tbestTest 0.6368887647\t\ttotal: 3m 7s\tremaining: 10m 51s\n",
      "268:\tlearn 0.655814062\ttest 0.6369346618\tbestTest 0.6369346618\t\ttotal: 3m 8s\tremaining: 10m 51s\n",
      "269:\tlearn 0.6559706439\ttest 0.6369662209\tbestTest 0.6369662209\t\ttotal: 3m 8s\tremaining: 10m 50s\n",
      "270:\tlearn 0.6560455643\ttest 0.637019956\tbestTest 0.637019956\t\ttotal: 3m 9s\tremaining: 10m 49s\n",
      "271:\tlearn 0.6561111402\ttest 0.637022128\tbestTest 0.637022128\t\ttotal: 3m 10s\tremaining: 10m 49s\n",
      "272:\tlearn 0.6561552855\ttest 0.6370345833\tbestTest 0.6370345833\t\ttotal: 3m 10s\tremaining: 10m 48s\n",
      "273:\tlearn 0.6562749972\ttest 0.6370406452\tbestTest 0.6370406452\t\ttotal: 3m 11s\tremaining: 10m 47s\n",
      "274:\tlearn 0.6563926905\ttest 0.6370074023\tbestTest 0.6370406452\t\ttotal: 3m 12s\tremaining: 10m 46s\n",
      "275:\tlearn 0.6564212804\ttest 0.6370244527\tbestTest 0.6370406452\t\ttotal: 3m 12s\tremaining: 10m 45s\n",
      "276:\tlearn 0.6566649518\ttest 0.6370899579\tbestTest 0.6370899579\t\ttotal: 3m 13s\tremaining: 10m 45s\n",
      "277:\tlearn 0.6568726305\ttest 0.637110621\tbestTest 0.637110621\t\ttotal: 3m 14s\tremaining: 10m 44s\n",
      "278:\tlearn 0.6569542889\ttest 0.6371374182\tbestTest 0.6371374182\t\ttotal: 3m 14s\tremaining: 10m 43s\n",
      "279:\tlearn 0.6572229544\ttest 0.6372323829\tbestTest 0.6372323829\t\ttotal: 3m 15s\tremaining: 10m 42s\n",
      "280:\tlearn 0.6573768392\ttest 0.6372754068\tbestTest 0.6372754068\t\ttotal: 3m 16s\tremaining: 10m 42s\n",
      "281:\tlearn 0.6574680469\ttest 0.6372828631\tbestTest 0.6372828631\t\ttotal: 3m 17s\tremaining: 10m 41s\n",
      "282:\tlearn 0.6574976581\ttest 0.6372823306\tbestTest 0.6372828631\t\ttotal: 3m 17s\tremaining: 10m 40s\n",
      "283:\tlearn 0.6575804856\ttest 0.637251971\tbestTest 0.6372828631\t\ttotal: 3m 18s\tremaining: 10m 40s\n",
      "284:\tlearn 0.6577779917\ttest 0.6373198893\tbestTest 0.6373198893\t\ttotal: 3m 19s\tremaining: 10m 39s\n",
      "285:\tlearn 0.6580233936\ttest 0.6373778237\tbestTest 0.6373778237\t\ttotal: 3m 19s\tremaining: 10m 39s\n",
      "286:\tlearn 0.6580835324\ttest 0.6373977032\tbestTest 0.6373977032\t\ttotal: 3m 20s\tremaining: 10m 38s\n",
      "287:\tlearn 0.6581901195\ttest 0.637492919\tbestTest 0.637492919\t\ttotal: 3m 21s\tremaining: 10m 37s\n",
      "288:\tlearn 0.6582122597\ttest 0.6374625433\tbestTest 0.637492919\t\ttotal: 3m 22s\tremaining: 10m 36s\n",
      "289:\tlearn 0.6583359207\ttest 0.6375003492\tbestTest 0.6375003492\t\ttotal: 3m 22s\tremaining: 10m 35s\n",
      "290:\tlearn 0.6583527294\ttest 0.6375165356\tbestTest 0.6375165356\t\ttotal: 3m 23s\tremaining: 10m 35s\n",
      "291:\tlearn 0.6585053491\ttest 0.637484653\tbestTest 0.6375165356\t\ttotal: 3m 24s\tremaining: 10m 34s\n",
      "292:\tlearn 0.6585975132\ttest 0.6375042974\tbestTest 0.6375165356\t\ttotal: 3m 24s\tremaining: 10m 33s\n",
      "293:\tlearn 0.6585899151\ttest 0.6375023022\tbestTest 0.6375165356\t\ttotal: 3m 25s\tremaining: 10m 32s\n",
      "294:\tlearn 0.6586818378\ttest 0.6376083298\tbestTest 0.6376083298\t\ttotal: 3m 26s\tremaining: 10m 31s\n",
      "295:\tlearn 0.6588304532\ttest 0.6376397563\tbestTest 0.6376397563\t\ttotal: 3m 26s\tremaining: 10m 31s\n",
      "296:\tlearn 0.6588643335\ttest 0.6376435196\tbestTest 0.6376435196\t\ttotal: 3m 27s\tremaining: 10m 30s\n",
      "297:\tlearn 0.6589508978\ttest 0.6376764892\tbestTest 0.6376764892\t\ttotal: 3m 28s\tremaining: 10m 29s\n",
      "298:\tlearn 0.6589938222\ttest 0.6377020889\tbestTest 0.6377020889\t\ttotal: 3m 28s\tremaining: 10m 29s\n",
      "299:\tlearn 0.6590524282\ttest 0.6377140359\tbestTest 0.6377140359\t\ttotal: 3m 29s\tremaining: 10m 28s\n",
      "300:\tlearn 0.6591238964\ttest 0.6377561958\tbestTest 0.6377561958\t\ttotal: 3m 30s\tremaining: 10m 27s\n",
      "301:\tlearn 0.6592357355\ttest 0.6377579137\tbestTest 0.6377579137\t\ttotal: 3m 30s\tremaining: 10m 26s\n",
      "302:\tlearn 0.6593598588\ttest 0.6377796577\tbestTest 0.6377796577\t\ttotal: 3m 31s\tremaining: 10m 26s\n",
      "303:\tlearn 0.6595673818\ttest 0.6378702824\tbestTest 0.6378702824\t\ttotal: 3m 32s\tremaining: 10m 25s\n",
      "304:\tlearn 0.6597490329\ttest 0.6379030792\tbestTest 0.6379030792\t\ttotal: 3m 32s\tremaining: 10m 24s\n",
      "305:\tlearn 0.6597592604\ttest 0.6378972766\tbestTest 0.6379030792\t\ttotal: 3m 33s\tremaining: 10m 23s\n",
      "306:\tlearn 0.6597962526\ttest 0.6378953919\tbestTest 0.6379030792\t\ttotal: 3m 34s\tremaining: 10m 22s\n",
      "307:\tlearn 0.6599518787\ttest 0.6379824161\tbestTest 0.6379824161\t\ttotal: 3m 34s\tremaining: 10m 21s\n",
      "308:\tlearn 0.6601177103\ttest 0.63800197\tbestTest 0.63800197\t\ttotal: 3m 35s\tremaining: 10m 21s\n",
      "309:\tlearn 0.6602048483\ttest 0.637983045\tbestTest 0.63800197\t\ttotal: 3m 36s\tremaining: 10m 20s\n",
      "310:\tlearn 0.6603794614\ttest 0.6379932579\tbestTest 0.63800197\t\ttotal: 3m 36s\tremaining: 10m 19s\n",
      "311:\tlearn 0.6604653621\ttest 0.6379766395\tbestTest 0.63800197\t\ttotal: 3m 37s\tremaining: 10m 18s\n",
      "312:\tlearn 0.6606524629\ttest 0.6380590565\tbestTest 0.6380590565\t\ttotal: 3m 38s\tremaining: 10m 17s\n",
      "313:\tlearn 0.6608401901\ttest 0.6381000531\tbestTest 0.6381000531\t\ttotal: 3m 38s\tremaining: 10m 17s\n",
      "314:\tlearn 0.6608707508\ttest 0.6381460908\tbestTest 0.6381460908\t\ttotal: 3m 39s\tremaining: 10m 16s\n",
      "315:\tlearn 0.6609330601\ttest 0.6381929623\tbestTest 0.6381929623\t\ttotal: 3m 40s\tremaining: 10m 15s\n",
      "316:\tlearn 0.6609816991\ttest 0.6382422409\tbestTest 0.6382422409\t\ttotal: 3m 40s\tremaining: 10m 14s\n",
      "317:\tlearn 0.6610799044\ttest 0.6382119938\tbestTest 0.6382422409\t\ttotal: 3m 41s\tremaining: 10m 14s\n",
      "318:\tlearn 0.661231682\ttest 0.6382552367\tbestTest 0.6382552367\t\ttotal: 3m 42s\tremaining: 10m 13s\n",
      "319:\tlearn 0.6614012669\ttest 0.6383197313\tbestTest 0.6383197313\t\ttotal: 3m 42s\tremaining: 10m 12s\n",
      "320:\tlearn 0.6615734571\ttest 0.638311192\tbestTest 0.6383197313\t\ttotal: 3m 43s\tremaining: 10m 11s\n",
      "321:\tlearn 0.6616951446\ttest 0.6383733679\tbestTest 0.6383733679\t\ttotal: 3m 44s\tremaining: 10m 11s\n",
      "322:\tlearn 0.6619433456\ttest 0.6383598377\tbestTest 0.6383733679\t\ttotal: 3m 44s\tremaining: 10m 10s\n",
      "323:\tlearn 0.66211237\ttest 0.6383787708\tbestTest 0.6383787708\t\ttotal: 3m 45s\tremaining: 10m 9s\n",
      "324:\tlearn 0.6621960166\ttest 0.6383933378\tbestTest 0.6383933378\t\ttotal: 3m 46s\tremaining: 10m 8s\n",
      "325:\tlearn 0.6623180393\ttest 0.6383439607\tbestTest 0.6383933378\t\ttotal: 3m 46s\tremaining: 10m 8s\n",
      "326:\tlearn 0.662478336\ttest 0.6383533358\tbestTest 0.6383933378\t\ttotal: 3m 47s\tremaining: 10m 7s\n",
      "327:\tlearn 0.662590564\ttest 0.638337722\tbestTest 0.6383933378\t\ttotal: 3m 48s\tremaining: 10m 6s\n",
      "328:\tlearn 0.662701475\ttest 0.6384091766\tbestTest 0.6384091766\t\ttotal: 3m 48s\tremaining: 10m 5s\n",
      "329:\tlearn 0.662830214\ttest 0.6384336632\tbestTest 0.6384336632\t\ttotal: 3m 49s\tremaining: 10m 4s\n",
      "330:\tlearn 0.6629479097\ttest 0.6384111316\tbestTest 0.6384336632\t\ttotal: 3m 50s\tremaining: 10m 4s\n",
      "331:\tlearn 0.6630921573\ttest 0.6384122146\tbestTest 0.6384336632\t\ttotal: 3m 51s\tremaining: 10m 5s\n",
      "332:\tlearn 0.6632100483\ttest 0.6383826647\tbestTest 0.6384336632\t\ttotal: 3m 52s\tremaining: 10m 4s\n",
      "333:\tlearn 0.6633113078\ttest 0.638425775\tbestTest 0.6384336632\t\ttotal: 3m 52s\tremaining: 10m 3s\n",
      "334:\tlearn 0.6634306692\ttest 0.6384636873\tbestTest 0.6384636873\t\ttotal: 3m 53s\tremaining: 10m 3s\n",
      "335:\tlearn 0.6635959693\ttest 0.6385202795\tbestTest 0.6385202795\t\ttotal: 3m 54s\tremaining: 10m 2s\n",
      "336:\tlearn 0.6636688667\ttest 0.638501893\tbestTest 0.6385202795\t\ttotal: 3m 54s\tremaining: 10m 1s\n",
      "337:\tlearn 0.6637494354\ttest 0.6385122305\tbestTest 0.6385202795\t\ttotal: 3m 55s\tremaining: 10m\n",
      "338:\tlearn 0.6638497641\ttest 0.6385657768\tbestTest 0.6385657768\t\ttotal: 3m 56s\tremaining: 10m\n",
      "339:\tlearn 0.6639191459\ttest 0.6386094355\tbestTest 0.6386094355\t\ttotal: 3m 56s\tremaining: 9m 59s\n",
      "340:\tlearn 0.6640610432\ttest 0.6385993271\tbestTest 0.6386094355\t\ttotal: 3m 57s\tremaining: 9m 58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341:\tlearn 0.6640959427\ttest 0.6385692467\tbestTest 0.6386094355\t\ttotal: 3m 58s\tremaining: 9m 57s\n",
      "342:\tlearn 0.6641635293\ttest 0.6385761887\tbestTest 0.6386094355\t\ttotal: 3m 58s\tremaining: 9m 56s\n",
      "343:\tlearn 0.6643249115\ttest 0.6386452121\tbestTest 0.6386452121\t\ttotal: 3m 59s\tremaining: 9m 56s\n",
      "344:\tlearn 0.6643790523\ttest 0.638660844\tbestTest 0.638660844\t\ttotal: 4m\tremaining: 9m 55s\n",
      "345:\tlearn 0.664447999\ttest 0.6386896002\tbestTest 0.6386896002\t\ttotal: 4m\tremaining: 9m 54s\n",
      "346:\tlearn 0.6645080638\ttest 0.6386851779\tbestTest 0.6386896002\t\ttotal: 4m 1s\tremaining: 9m 53s\n",
      "347:\tlearn 0.6645675857\ttest 0.6387419108\tbestTest 0.6387419108\t\ttotal: 4m 2s\tremaining: 9m 53s\n",
      "348:\tlearn 0.6646140062\ttest 0.6387671348\tbestTest 0.6387671348\t\ttotal: 4m 2s\tremaining: 9m 52s\n",
      "349:\tlearn 0.6648024202\ttest 0.6387656982\tbestTest 0.6387671348\t\ttotal: 4m 3s\tremaining: 9m 51s\n",
      "350:\tlearn 0.6649143719\ttest 0.6387840948\tbestTest 0.6387840948\t\ttotal: 4m 4s\tremaining: 9m 50s\n",
      "351:\tlearn 0.6649518853\ttest 0.6388032187\tbestTest 0.6388032187\t\ttotal: 4m 4s\tremaining: 9m 50s\n",
      "352:\tlearn 0.6651004027\ttest 0.6387774221\tbestTest 0.6388032187\t\ttotal: 4m 5s\tremaining: 9m 49s\n",
      "353:\tlearn 0.6651315835\ttest 0.6387618987\tbestTest 0.6388032187\t\ttotal: 4m 6s\tremaining: 9m 48s\n",
      "354:\tlearn 0.6652246283\ttest 0.6387565641\tbestTest 0.6388032187\t\ttotal: 4m 7s\tremaining: 9m 48s\n",
      "355:\tlearn 0.6653357535\ttest 0.638793279\tbestTest 0.6388032187\t\ttotal: 4m 7s\tremaining: 9m 47s\n",
      "356:\tlearn 0.665409913\ttest 0.6388246472\tbestTest 0.6388246472\t\ttotal: 4m 8s\tremaining: 9m 46s\n",
      "357:\tlearn 0.6654673294\ttest 0.6388263571\tbestTest 0.6388263571\t\ttotal: 4m 9s\tremaining: 9m 45s\n",
      "358:\tlearn 0.6655195564\ttest 0.6388375566\tbestTest 0.6388375566\t\ttotal: 4m 9s\tremaining: 9m 45s\n",
      "359:\tlearn 0.6656488925\ttest 0.6388374079\tbestTest 0.6388375566\t\ttotal: 4m 10s\tremaining: 9m 44s\n",
      "360:\tlearn 0.6657122433\ttest 0.6388242414\tbestTest 0.6388375566\t\ttotal: 4m 11s\tremaining: 9m 43s\n",
      "361:\tlearn 0.6657709423\ttest 0.6387531967\tbestTest 0.6388375566\t\ttotal: 4m 11s\tremaining: 9m 42s\n",
      "362:\tlearn 0.6658688022\ttest 0.6387340486\tbestTest 0.6388375566\t\ttotal: 4m 12s\tremaining: 9m 42s\n",
      "363:\tlearn 0.6659435458\ttest 0.6387386598\tbestTest 0.6388375566\t\ttotal: 4m 13s\tremaining: 9m 41s\n",
      "364:\tlearn 0.6660284844\ttest 0.6387268374\tbestTest 0.6388375566\t\ttotal: 4m 13s\tremaining: 9m 40s\n",
      "365:\tlearn 0.6661354564\ttest 0.6387535664\tbestTest 0.6388375566\t\ttotal: 4m 14s\tremaining: 9m 39s\n",
      "366:\tlearn 0.6662475344\ttest 0.6387593791\tbestTest 0.6388375566\t\ttotal: 4m 15s\tremaining: 9m 39s\n",
      "367:\tlearn 0.6665204762\ttest 0.6388524873\tbestTest 0.6388524873\t\ttotal: 4m 15s\tremaining: 9m 38s\n",
      "368:\tlearn 0.6666127308\ttest 0.6388419187\tbestTest 0.6388524873\t\ttotal: 4m 16s\tremaining: 9m 37s\n",
      "369:\tlearn 0.6666413393\ttest 0.6388180549\tbestTest 0.6388524873\t\ttotal: 4m 17s\tremaining: 9m 36s\n",
      "370:\tlearn 0.6666735938\ttest 0.6388369518\tbestTest 0.6388524873\t\ttotal: 4m 17s\tremaining: 9m 36s\n",
      "371:\tlearn 0.6667091016\ttest 0.6387841309\tbestTest 0.6388524873\t\ttotal: 4m 18s\tremaining: 9m 35s\n",
      "372:\tlearn 0.6667451847\ttest 0.6387971849\tbestTest 0.6388524873\t\ttotal: 4m 19s\tremaining: 9m 34s\n",
      "373:\tlearn 0.6668838904\ttest 0.638807209\tbestTest 0.6388524873\t\ttotal: 4m 19s\tremaining: 9m 33s\n",
      "374:\tlearn 0.666949548\ttest 0.6388118042\tbestTest 0.6388524873\t\ttotal: 4m 20s\tremaining: 9m 33s\n",
      "375:\tlearn 0.6669578695\ttest 0.6388214304\tbestTest 0.6388524873\t\ttotal: 4m 22s\tremaining: 9m 34s\n",
      "376:\tlearn 0.6669969286\ttest 0.6388252822\tbestTest 0.6388524873\t\ttotal: 4m 23s\tremaining: 9m 34s\n",
      "377:\tlearn 0.6670498258\ttest 0.6388482056\tbestTest 0.6388524873\t\ttotal: 4m 23s\tremaining: 9m 33s\n",
      "378:\tlearn 0.6671404749\ttest 0.6388674541\tbestTest 0.6388674541\t\ttotal: 4m 24s\tremaining: 9m 32s\n",
      "379:\tlearn 0.667168383\ttest 0.6388917398\tbestTest 0.6388917398\t\ttotal: 4m 25s\tremaining: 9m 31s\n",
      "380:\tlearn 0.6672720701\ttest 0.6389029232\tbestTest 0.6389029232\t\ttotal: 4m 25s\tremaining: 9m 31s\n",
      "381:\tlearn 0.6673289253\ttest 0.638894609\tbestTest 0.6389029232\t\ttotal: 4m 26s\tremaining: 9m 30s\n",
      "382:\tlearn 0.6674434388\ttest 0.6388999355\tbestTest 0.6389029232\t\ttotal: 4m 27s\tremaining: 9m 29s\n",
      "383:\tlearn 0.6674648176\ttest 0.6388989067\tbestTest 0.6389029232\t\ttotal: 4m 27s\tremaining: 9m 28s\n",
      "384:\tlearn 0.667509556\ttest 0.6389099375\tbestTest 0.6389099375\t\ttotal: 4m 28s\tremaining: 9m 28s\n",
      "385:\tlearn 0.6675981016\ttest 0.6388899536\tbestTest 0.6389099375\t\ttotal: 4m 29s\tremaining: 9m 27s\n",
      "386:\tlearn 0.6676614845\ttest 0.6388979102\tbestTest 0.6389099375\t\ttotal: 4m 29s\tremaining: 9m 26s\n",
      "387:\tlearn 0.6677070366\ttest 0.6389131784\tbestTest 0.6389131784\t\ttotal: 4m 30s\tremaining: 9m 25s\n",
      "388:\tlearn 0.6677303674\ttest 0.6389315428\tbestTest 0.6389315428\t\ttotal: 4m 30s\tremaining: 9m 24s\n",
      "389:\tlearn 0.6678307877\ttest 0.6389700941\tbestTest 0.6389700941\t\ttotal: 4m 31s\tremaining: 9m 24s\n",
      "390:\tlearn 0.6678925128\ttest 0.6389703553\tbestTest 0.6389703553\t\ttotal: 4m 32s\tremaining: 9m 23s\n",
      "391:\tlearn 0.6679738012\ttest 0.6389874138\tbestTest 0.6389874138\t\ttotal: 4m 32s\tremaining: 9m 22s\n",
      "392:\tlearn 0.6680917917\ttest 0.6389563368\tbestTest 0.6389874138\t\ttotal: 4m 33s\tremaining: 9m 22s\n",
      "393:\tlearn 0.6681222052\ttest 0.638952467\tbestTest 0.6389874138\t\ttotal: 4m 34s\tremaining: 9m 21s\n",
      "394:\tlearn 0.6681699149\ttest 0.6389648741\tbestTest 0.6389874138\t\ttotal: 4m 35s\tremaining: 9m 20s\n",
      "395:\tlearn 0.6682356144\ttest 0.6390023062\tbestTest 0.6390023062\t\ttotal: 4m 35s\tremaining: 9m 19s\n",
      "396:\tlearn 0.6683207091\ttest 0.6389734937\tbestTest 0.6390023062\t\ttotal: 4m 36s\tremaining: 9m 19s\n",
      "397:\tlearn 0.6684256488\ttest 0.6390203492\tbestTest 0.6390203492\t\ttotal: 4m 37s\tremaining: 9m 18s\n",
      "398:\tlearn 0.6685349327\ttest 0.6390443697\tbestTest 0.6390443697\t\ttotal: 4m 37s\tremaining: 9m 17s\n",
      "399:\tlearn 0.6686633105\ttest 0.6390119606\tbestTest 0.6390443697\t\ttotal: 4m 38s\tremaining: 9m 17s\n",
      "400:\tlearn 0.6687162648\ttest 0.6390633871\tbestTest 0.6390633871\t\ttotal: 4m 39s\tremaining: 9m 16s\n",
      "401:\tlearn 0.6687955197\ttest 0.6390617335\tbestTest 0.6390633871\t\ttotal: 4m 39s\tremaining: 9m 15s\n",
      "402:\tlearn 0.6689367117\ttest 0.6390939959\tbestTest 0.6390939959\t\ttotal: 4m 40s\tremaining: 9m 14s\n",
      "403:\tlearn 0.6689650742\ttest 0.6391096358\tbestTest 0.6391096358\t\ttotal: 4m 41s\tremaining: 9m 14s\n",
      "404:\tlearn 0.6690129535\ttest 0.6391019203\tbestTest 0.6391096358\t\ttotal: 4m 41s\tremaining: 9m 13s\n",
      "405:\tlearn 0.6691233462\ttest 0.6391651029\tbestTest 0.6391651029\t\ttotal: 4m 42s\tremaining: 9m 12s\n",
      "406:\tlearn 0.6692469661\ttest 0.6391907428\tbestTest 0.6391907428\t\ttotal: 4m 43s\tremaining: 9m 11s\n",
      "407:\tlearn 0.6693869943\ttest 0.63924537\tbestTest 0.63924537\t\ttotal: 4m 43s\tremaining: 9m 11s\n",
      "408:\tlearn 0.6694408152\ttest 0.6392341946\tbestTest 0.63924537\t\ttotal: 4m 44s\tremaining: 9m 10s\n",
      "409:\tlearn 0.6694771616\ttest 0.639203176\tbestTest 0.63924537\t\ttotal: 4m 45s\tremaining: 9m 9s\n",
      "410:\tlearn 0.669534038\ttest 0.6392352917\tbestTest 0.63924537\t\ttotal: 4m 46s\tremaining: 9m 9s\n",
      "411:\tlearn 0.6696284363\ttest 0.6392113295\tbestTest 0.63924537\t\ttotal: 4m 46s\tremaining: 9m 8s\n",
      "412:\tlearn 0.669749873\ttest 0.6392660451\tbestTest 0.6392660451\t\ttotal: 4m 47s\tremaining: 9m 7s\n",
      "413:\tlearn 0.6698348378\ttest 0.6392755287\tbestTest 0.6392755287\t\ttotal: 4m 48s\tremaining: 9m 6s\n",
      "414:\tlearn 0.6699681474\ttest 0.6392724706\tbestTest 0.6392755287\t\ttotal: 4m 48s\tremaining: 9m 6s\n",
      "415:\tlearn 0.6700354144\ttest 0.6392434813\tbestTest 0.6392755287\t\ttotal: 4m 49s\tremaining: 9m 5s\n",
      "416:\tlearn 0.670156162\ttest 0.6392543292\tbestTest 0.6392755287\t\ttotal: 4m 50s\tremaining: 9m 4s\n",
      "417:\tlearn 0.6702590794\ttest 0.6392730312\tbestTest 0.6392755287\t\ttotal: 4m 50s\tremaining: 9m 4s\n",
      "418:\tlearn 0.6703114615\ttest 0.6392842749\tbestTest 0.6392842749\t\ttotal: 4m 51s\tremaining: 9m 3s\n",
      "419:\tlearn 0.6704061167\ttest 0.6393003428\tbestTest 0.6393003428\t\ttotal: 4m 52s\tremaining: 9m 2s\n",
      "420:\tlearn 0.6706118186\ttest 0.6392892217\tbestTest 0.6393003428\t\ttotal: 4m 52s\tremaining: 9m 2s\n",
      "421:\tlearn 0.670670705\ttest 0.6392654604\tbestTest 0.6393003428\t\ttotal: 4m 53s\tremaining: 9m 1s\n",
      "422:\tlearn 0.6708181805\ttest 0.639305171\tbestTest 0.639305171\t\ttotal: 4m 54s\tremaining: 9m\n",
      "423:\tlearn 0.6709653687\ttest 0.639295808\tbestTest 0.639305171\t\ttotal: 4m 54s\tremaining: 8m 59s\n",
      "424:\tlearn 0.6709994296\ttest 0.6392865293\tbestTest 0.639305171\t\ttotal: 4m 55s\tremaining: 8m 59s\n",
      "425:\tlearn 0.671099087\ttest 0.6393370014\tbestTest 0.6393370014\t\ttotal: 4m 56s\tremaining: 8m 58s\n",
      "426:\tlearn 0.6711745303\ttest 0.6393530412\tbestTest 0.6393530412\t\ttotal: 4m 57s\tremaining: 8m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427:\tlearn 0.6711946461\ttest 0.6393528181\tbestTest 0.6393530412\t\ttotal: 4m 57s\tremaining: 8m 56s\n",
      "428:\tlearn 0.6712513038\ttest 0.639378448\tbestTest 0.639378448\t\ttotal: 4m 58s\tremaining: 8m 56s\n",
      "429:\tlearn 0.671336326\ttest 0.6393115363\tbestTest 0.639378448\t\ttotal: 4m 59s\tremaining: 8m 55s\n",
      "430:\tlearn 0.6713851614\ttest 0.6393053117\tbestTest 0.639378448\t\ttotal: 4m 59s\tremaining: 8m 54s\n",
      "431:\tlearn 0.6714867574\ttest 0.6393455246\tbestTest 0.639378448\t\ttotal: 5m\tremaining: 8m 54s\n",
      "432:\tlearn 0.6715987701\ttest 0.6393084401\tbestTest 0.639378448\t\ttotal: 5m 1s\tremaining: 8m 53s\n",
      "433:\tlearn 0.6716481948\ttest 0.6393119602\tbestTest 0.639378448\t\ttotal: 5m 1s\tremaining: 8m 52s\n",
      "434:\tlearn 0.671723352\ttest 0.6392972606\tbestTest 0.639378448\t\ttotal: 5m 2s\tremaining: 8m 51s\n",
      "435:\tlearn 0.6718440958\ttest 0.6392370558\tbestTest 0.639378448\t\ttotal: 5m 3s\tremaining: 8m 51s\n",
      "436:\tlearn 0.6718896318\ttest 0.6392372868\tbestTest 0.639378448\t\ttotal: 5m 3s\tremaining: 8m 50s\n",
      "437:\tlearn 0.6719818602\ttest 0.6392619704\tbestTest 0.639378448\t\ttotal: 5m 4s\tremaining: 8m 49s\n",
      "438:\tlearn 0.6720023633\ttest 0.6392548114\tbestTest 0.639378448\t\ttotal: 5m 5s\tremaining: 8m 48s\n",
      "439:\tlearn 0.6720876819\ttest 0.6392796195\tbestTest 0.639378448\t\ttotal: 5m 5s\tremaining: 8m 48s\n",
      "440:\tlearn 0.672135178\ttest 0.6392409276\tbestTest 0.639378448\t\ttotal: 5m 6s\tremaining: 8m 47s\n",
      "441:\tlearn 0.6721801306\ttest 0.6392240058\tbestTest 0.639378448\t\ttotal: 5m 7s\tremaining: 8m 46s\n",
      "442:\tlearn 0.6722859211\ttest 0.6391989988\tbestTest 0.639378448\t\ttotal: 5m 7s\tremaining: 8m 46s\n",
      "443:\tlearn 0.6723429214\ttest 0.6392651711\tbestTest 0.639378448\t\ttotal: 5m 8s\tremaining: 8m 45s\n",
      "444:\tlearn 0.6723948796\ttest 0.639240801\tbestTest 0.639378448\t\ttotal: 5m 9s\tremaining: 8m 44s\n",
      "445:\tlearn 0.6724437526\ttest 0.6392486893\tbestTest 0.639378448\t\ttotal: 5m 9s\tremaining: 8m 43s\n",
      "446:\tlearn 0.6725084953\ttest 0.6392168328\tbestTest 0.639378448\t\ttotal: 5m 10s\tremaining: 8m 43s\n",
      "447:\tlearn 0.6725936005\ttest 0.6392239073\tbestTest 0.639378448\t\ttotal: 5m 11s\tremaining: 8m 42s\n",
      "448:\tlearn 0.6726698346\ttest 0.6392036361\tbestTest 0.639378448\t\ttotal: 5m 11s\tremaining: 8m 41s\n",
      "449:\tlearn 0.6727405474\ttest 0.6391726576\tbestTest 0.639378448\t\ttotal: 5m 12s\tremaining: 8m 40s\n",
      "450:\tlearn 0.6727601681\ttest 0.6391533207\tbestTest 0.639378448\t\ttotal: 5m 13s\tremaining: 8m 40s\n",
      "451:\tlearn 0.6728472203\ttest 0.6391291415\tbestTest 0.639378448\t\ttotal: 5m 13s\tremaining: 8m 39s\n",
      "452:\tlearn 0.6729491843\ttest 0.6391193143\tbestTest 0.639378448\t\ttotal: 5m 14s\tremaining: 8m 38s\n",
      "453:\tlearn 0.6731147966\ttest 0.6391208675\tbestTest 0.639378448\t\ttotal: 5m 15s\tremaining: 8m 38s\n",
      "454:\tlearn 0.6732250059\ttest 0.6391265757\tbestTest 0.639378448\t\ttotal: 5m 15s\tremaining: 8m 37s\n",
      "455:\tlearn 0.6732979179\ttest 0.6390925673\tbestTest 0.639378448\t\ttotal: 5m 16s\tremaining: 8m 36s\n",
      "456:\tlearn 0.6733923805\ttest 0.6391393424\tbestTest 0.639378448\t\ttotal: 5m 17s\tremaining: 8m 35s\n",
      "457:\tlearn 0.673473509\ttest 0.6391142008\tbestTest 0.639378448\t\ttotal: 5m 17s\tremaining: 8m 35s\n",
      "458:\tlearn 0.67357817\ttest 0.6391558483\tbestTest 0.639378448\t\ttotal: 5m 18s\tremaining: 8m 34s\n",
      "459:\tlearn 0.6736598124\ttest 0.639165561\tbestTest 0.639378448\t\ttotal: 5m 19s\tremaining: 8m 33s\n",
      "460:\tlearn 0.6737841122\ttest 0.6391580103\tbestTest 0.639378448\t\ttotal: 5m 20s\tremaining: 8m 33s\n",
      "461:\tlearn 0.6738421498\ttest 0.6391434895\tbestTest 0.639378448\t\ttotal: 5m 20s\tremaining: 8m 32s\n",
      "462:\tlearn 0.6739061368\ttest 0.6391647774\tbestTest 0.639378448\t\ttotal: 5m 21s\tremaining: 8m 31s\n",
      "463:\tlearn 0.6739435381\ttest 0.6391617354\tbestTest 0.639378448\t\ttotal: 5m 22s\tremaining: 8m 30s\n",
      "464:\tlearn 0.6740112881\ttest 0.6391769755\tbestTest 0.639378448\t\ttotal: 5m 22s\tremaining: 8m 30s\n",
      "465:\tlearn 0.6740707619\ttest 0.6391672829\tbestTest 0.639378448\t\ttotal: 5m 23s\tremaining: 8m 29s\n",
      "466:\tlearn 0.6741510872\ttest 0.6391567987\tbestTest 0.639378448\t\ttotal: 5m 24s\tremaining: 8m 28s\n",
      "467:\tlearn 0.6742265027\ttest 0.6391712451\tbestTest 0.639378448\t\ttotal: 5m 24s\tremaining: 8m 28s\n",
      "468:\tlearn 0.6743143641\ttest 0.6391743132\tbestTest 0.639378448\t\ttotal: 5m 25s\tremaining: 8m 27s\n",
      "469:\tlearn 0.6743517612\ttest 0.6391746448\tbestTest 0.639378448\t\ttotal: 5m 26s\tremaining: 8m 26s\n",
      "470:\tlearn 0.6744416651\ttest 0.6391780022\tbestTest 0.639378448\t\ttotal: 5m 26s\tremaining: 8m 25s\n",
      "471:\tlearn 0.6745290782\ttest 0.6391756132\tbestTest 0.639378448\t\ttotal: 5m 27s\tremaining: 8m 25s\n",
      "472:\tlearn 0.6746038926\ttest 0.6391460412\tbestTest 0.639378448\t\ttotal: 5m 28s\tremaining: 8m 24s\n",
      "473:\tlearn 0.6746855734\ttest 0.639152736\tbestTest 0.639378448\t\ttotal: 5m 28s\tremaining: 8m 23s\n",
      "474:\tlearn 0.6747451923\ttest 0.6391341948\tbestTest 0.639378448\t\ttotal: 5m 29s\tremaining: 8m 22s\n",
      "475:\tlearn 0.6748804606\ttest 0.6392082292\tbestTest 0.639378448\t\ttotal: 5m 30s\tremaining: 8m 22s\n",
      "476:\tlearn 0.6749904731\ttest 0.6392017635\tbestTest 0.639378448\t\ttotal: 5m 30s\tremaining: 8m 21s\n",
      "477:\tlearn 0.6750487132\ttest 0.6392633648\tbestTest 0.639378448\t\ttotal: 5m 31s\tremaining: 8m 20s\n",
      "478:\tlearn 0.6751122617\ttest 0.6392899229\tbestTest 0.639378448\t\ttotal: 5m 32s\tremaining: 8m 19s\n",
      "479:\tlearn 0.6752023948\ttest 0.6392848496\tbestTest 0.639378448\t\ttotal: 5m 32s\tremaining: 8m 19s\n",
      "480:\tlearn 0.6752485973\ttest 0.6393056834\tbestTest 0.639378448\t\ttotal: 5m 33s\tremaining: 8m 18s\n",
      "481:\tlearn 0.675322397\ttest 0.6392974234\tbestTest 0.639378448\t\ttotal: 5m 34s\tremaining: 8m 17s\n",
      "482:\tlearn 0.6753641019\ttest 0.6392991915\tbestTest 0.639378448\t\ttotal: 5m 34s\tremaining: 8m 16s\n",
      "483:\tlearn 0.6754128705\ttest 0.6392851148\tbestTest 0.639378448\t\ttotal: 5m 35s\tremaining: 8m 16s\n",
      "484:\tlearn 0.6754990897\ttest 0.6393130553\tbestTest 0.639378448\t\ttotal: 5m 36s\tremaining: 8m 15s\n",
      "485:\tlearn 0.6756777707\ttest 0.6393400916\tbestTest 0.639378448\t\ttotal: 5m 36s\tremaining: 8m 14s\n",
      "486:\tlearn 0.6757841545\ttest 0.639282545\tbestTest 0.639378448\t\ttotal: 5m 37s\tremaining: 8m 13s\n",
      "487:\tlearn 0.6758699888\ttest 0.6392643915\tbestTest 0.639378448\t\ttotal: 5m 37s\tremaining: 8m 13s\n",
      "488:\tlearn 0.6759301917\ttest 0.639271249\tbestTest 0.639378448\t\ttotal: 5m 38s\tremaining: 8m 12s\n",
      "489:\tlearn 0.6759746945\ttest 0.6392803067\tbestTest 0.639378448\t\ttotal: 5m 39s\tremaining: 8m 11s\n",
      "490:\tlearn 0.6761414156\ttest 0.6392404815\tbestTest 0.639378448\t\ttotal: 5m 39s\tremaining: 8m 10s\n",
      "491:\tlearn 0.6763145711\ttest 0.6392684059\tbestTest 0.639378448\t\ttotal: 5m 40s\tremaining: 8m 10s\n",
      "492:\tlearn 0.6763796853\ttest 0.6392363164\tbestTest 0.639378448\t\ttotal: 5m 41s\tremaining: 8m 9s\n",
      "493:\tlearn 0.6764899843\ttest 0.6392688922\tbestTest 0.639378448\t\ttotal: 5m 41s\tremaining: 8m 8s\n",
      "494:\tlearn 0.6765628234\ttest 0.6392891031\tbestTest 0.639378448\t\ttotal: 5m 42s\tremaining: 8m 7s\n",
      "495:\tlearn 0.6766309\ttest 0.6392701259\tbestTest 0.639378448\t\ttotal: 5m 43s\tremaining: 8m 7s\n",
      "496:\tlearn 0.6766607932\ttest 0.6392459688\tbestTest 0.639378448\t\ttotal: 5m 43s\tremaining: 8m 6s\n",
      "497:\tlearn 0.6768069161\ttest 0.6392706201\tbestTest 0.639378448\t\ttotal: 5m 44s\tremaining: 8m 5s\n",
      "498:\tlearn 0.6768575263\ttest 0.6392655589\tbestTest 0.639378448\t\ttotal: 5m 45s\tremaining: 8m 4s\n",
      "499:\tlearn 0.6768708877\ttest 0.6392794266\tbestTest 0.639378448\t\ttotal: 5m 45s\tremaining: 8m 4s\n",
      "500:\tlearn 0.6769724086\ttest 0.6392837364\tbestTest 0.639378448\t\ttotal: 5m 46s\tremaining: 8m 3s\n",
      "501:\tlearn 0.6770691282\ttest 0.6393265493\tbestTest 0.639378448\t\ttotal: 5m 47s\tremaining: 8m 2s\n",
      "502:\tlearn 0.6771503267\ttest 0.6393331919\tbestTest 0.639378448\t\ttotal: 5m 48s\tremaining: 8m 2s\n",
      "503:\tlearn 0.6772502401\ttest 0.6393614378\tbestTest 0.639378448\t\ttotal: 5m 48s\tremaining: 8m 1s\n",
      "504:\tlearn 0.6773252187\ttest 0.6393314278\tbestTest 0.639378448\t\ttotal: 5m 49s\tremaining: 8m\n",
      "505:\tlearn 0.6773864474\ttest 0.6393428081\tbestTest 0.639378448\t\ttotal: 5m 49s\tremaining: 7m 59s\n",
      "506:\tlearn 0.6774626748\ttest 0.6392968387\tbestTest 0.639378448\t\ttotal: 5m 50s\tremaining: 7m 59s\n",
      "507:\tlearn 0.6775211703\ttest 0.6392867804\tbestTest 0.639378448\t\ttotal: 5m 51s\tremaining: 7m 58s\n",
      "508:\tlearn 0.6775512844\ttest 0.639289075\tbestTest 0.639378448\t\ttotal: 5m 52s\tremaining: 7m 57s\n",
      "509:\tlearn 0.6776567826\ttest 0.6392853137\tbestTest 0.639378448\t\ttotal: 5m 52s\tremaining: 7m 57s\n",
      "510:\tlearn 0.6777507347\ttest 0.6392754785\tbestTest 0.639378448\t\ttotal: 5m 53s\tremaining: 7m 56s\n",
      "511:\tlearn 0.6778106688\ttest 0.6392854021\tbestTest 0.639378448\t\ttotal: 5m 54s\tremaining: 7m 55s\n",
      "512:\tlearn 0.6778762633\ttest 0.639266457\tbestTest 0.639378448\t\ttotal: 5m 54s\tremaining: 7m 55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513:\tlearn 0.6779818609\ttest 0.6392601058\tbestTest 0.639378448\t\ttotal: 5m 55s\tremaining: 7m 54s\n",
      "514:\tlearn 0.6780653937\ttest 0.6392253439\tbestTest 0.639378448\t\ttotal: 5m 56s\tremaining: 7m 53s\n",
      "515:\tlearn 0.67818244\ttest 0.6392192861\tbestTest 0.639378448\t\ttotal: 5m 56s\tremaining: 7m 53s\n",
      "516:\tlearn 0.678210276\ttest 0.639221239\tbestTest 0.639378448\t\ttotal: 5m 57s\tremaining: 7m 52s\n",
      "517:\tlearn 0.6782975176\ttest 0.639197522\tbestTest 0.639378448\t\ttotal: 5m 58s\tremaining: 7m 51s\n",
      "518:\tlearn 0.6783787974\ttest 0.6391920026\tbestTest 0.639378448\t\ttotal: 5m 58s\tremaining: 7m 50s\n",
      "519:\tlearn 0.6784224238\ttest 0.6391788742\tbestTest 0.639378448\t\ttotal: 5m 59s\tremaining: 7m 50s\n",
      "520:\tlearn 0.6784316104\ttest 0.639190789\tbestTest 0.639378448\t\ttotal: 6m\tremaining: 7m 49s\n",
      "521:\tlearn 0.6784544653\ttest 0.6391764993\tbestTest 0.639378448\t\ttotal: 6m\tremaining: 7m 48s\n",
      "522:\tlearn 0.6785614715\ttest 0.6391635116\tbestTest 0.639378448\t\ttotal: 6m 1s\tremaining: 7m 47s\n",
      "523:\tlearn 0.6786830838\ttest 0.6391646629\tbestTest 0.639378448\t\ttotal: 6m 2s\tremaining: 7m 47s\n",
      "524:\tlearn 0.6787513492\ttest 0.6391428445\tbestTest 0.639378448\t\ttotal: 6m 2s\tremaining: 7m 46s\n",
      "525:\tlearn 0.6788629843\ttest 0.6391458182\tbestTest 0.639378448\t\ttotal: 6m 3s\tremaining: 7m 45s\n",
      "526:\tlearn 0.6789415685\ttest 0.6391728726\tbestTest 0.639378448\t\ttotal: 6m 4s\tremaining: 7m 45s\n",
      "527:\tlearn 0.6790244904\ttest 0.6392022578\tbestTest 0.639378448\t\ttotal: 6m 5s\tremaining: 7m 44s\n",
      "528:\tlearn 0.6790586859\ttest 0.639214703\tbestTest 0.639378448\t\ttotal: 6m 5s\tremaining: 7m 43s\n",
      "529:\tlearn 0.679133742\ttest 0.6392763023\tbestTest 0.639378448\t\ttotal: 6m 6s\tremaining: 7m 43s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.639378448\n",
      "bestIteration = 428\n",
      "\n",
      "Shrink model to first 429 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7ff882e59048>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_early = CatBoostClassifier(iterations=1200, learning_rate=0.03, depth=8, loss_function='Logloss', eval_metric='AUC', random_seed=99, od_type='Iter', od_wait=100) \n",
    "cat_early.fit(train_train_x_fe, train_train_y, eval_set=(train_test_x_fe,train_test_y), use_best_model=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_early_pred = cat_early.predict(train_test_x_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_early_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191093    0\n",
       "409985    0\n",
       "54034     0\n",
       "400856    0\n",
       "469504    0\n",
       "184907    0\n",
       "180428    0\n",
       "153828    0\n",
       "4289      0\n",
       "460504    0\n",
       "470843    0\n",
       "174608    0\n",
       "52734     0\n",
       "499303    0\n",
       "420582    0\n",
       "388995    0\n",
       "189185    0\n",
       "247608    0\n",
       "481146    0\n",
       "588497    0\n",
       "47016     1\n",
       "130316    0\n",
       "538984    0\n",
       "299586    0\n",
       "271864    0\n",
       "590495    0\n",
       "112410    0\n",
       "209711    0\n",
       "112610    0\n",
       "360230    0\n",
       "         ..\n",
       "256082    0\n",
       "254452    0\n",
       "562931    0\n",
       "542760    0\n",
       "393656    0\n",
       "179668    0\n",
       "126631    0\n",
       "155724    0\n",
       "88154     0\n",
       "503233    0\n",
       "499176    0\n",
       "8512      0\n",
       "22514     0\n",
       "533326    0\n",
       "93960     0\n",
       "91304     0\n",
       "382114    0\n",
       "197514    0\n",
       "141291    0\n",
       "105344    0\n",
       "146730    0\n",
       "153157    0\n",
       "292372    0\n",
       "195660    0\n",
       "187126    0\n",
       "49304     0\n",
       "97290     0\n",
       "505638    0\n",
       "284309    0\n",
       "124773    0\n",
       "Name: target, Length: 119043, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CatBoost params\n",
    "cat_params1 = {}\n",
    "cat_params1['iterations'] = [429]\n",
    "cat_params1['depth'] = [8,6,10]\n",
    "cat_params1['rsm'] = [0.95]\n",
    "cat_params1['learning_rate'] = [0.03,.02]\n",
    "cat_params1['l2_leaf_reg'] = [3.5,2]\n",
    "cat_params1['border_count'] = [8,7,6]\n",
    "cat_params1['gradient_iterations'] = [5,4,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "[joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7740e91f6128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgsearch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_params1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgsearch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_fe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 547\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ImportError(\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0;34m'[joblib] Attempting to do parallel computing '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0;34m'without protecting your import on a system that does '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: [joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
     ]
    }
   ],
   "source": [
    "gsearch2 = GridSearchCV(estimator = CatBoostClassifier(), param_grid = cat_params1,iid=False,scoring = 'roc_auc', cv=3, n_jobs=-1)\n",
    "gsearch2.fit(train_x_fe,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_x_fe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 60)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Lightgbm + parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(train_train_x, train_train_y)\n",
    "d_valid = lgb.Dataset(train_test_x,train_test_y) \n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "\n",
    "print('Training LGBM model...')\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['application'] = 'binary'\n",
    "lgb_params['max_depth'] = 14\n",
    "lgb_params['num_leaves'] = 2**8\n",
    "lgb_params['verbosity'] = 0\n",
    "lgb_params['metric'] = 'auc'\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=1200, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=25, verbose_eval=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 8: LR stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
